{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlzpXrLLmwC1phUdqirLK1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthikasai1828/Coursera_projects/blob/main/reg_assignment_coursera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, we have to import necessary libraries.\n",
        "\n",
        "**numpy:** For numerical operations and handling arrays/matrices.\n",
        "\n",
        "**pandas:** For data manipulation and analysis with DataFrame objects.\n",
        "\n",
        "**matplotlib:** For data visualization and plotting.\n",
        "\n",
        "**keras.models.Sequential:** To build neural network models layer by layer.\n",
        "\n",
        "**keras.layers.Dense:** To create fully connected (dense) layers in neural networks.\n",
        "\n",
        "**sklearn.model_selection.train_test_split:** To split data into training and testing sets for model evaluation."
      ],
      "metadata": {
        "id": "hgYNO-v_N1NP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ALCyk-WZAZAq"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VfaGa6rPAnJK",
        "outputId": "78f223fa-1f27-427d-e94f-a881159ba926"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-711a4e16-759a-448f-80cb-19f217fc20e8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-711a4e16-759a-448f-80cb-19f217fc20e8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving concrete_data.csv to concrete_data (1).csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'concrete_data (1).csv': b'Cement,Blast Furnace Slag,Fly Ash,Water,Superplasticizer,Coarse Aggregate,Fine Aggregate,Age,Strength\\r\\n540.0 ,0.0 ,0.0 ,162.0 ,2.5 ,1040.0 ,676.0 ,28 ,79.99 \\r\\n540.0 ,0.0 ,0.0 ,162.0 ,2.5 ,1055.0 ,676.0 ,28 ,61.89 \\r\\n332.5 ,142.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,270 ,40.27 \\r\\n332.5 ,142.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,365 ,41.05 \\r\\n198.6 ,132.4 ,0.0 ,192.0 ,0.0 ,978.4 ,825.5 ,360 ,44.30 \\r\\n266.0 ,114.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,90 ,47.03 \\r\\n380.0 ,95.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,365 ,43.70 \\r\\n380.0 ,95.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,28 ,36.45 \\r\\n266.0 ,114.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,28 ,45.85 \\r\\n475.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,28 ,39.29 \\r\\n198.6 ,132.4 ,0.0 ,192.0 ,0.0 ,978.4 ,825.5 ,90 ,38.07 \\r\\n198.6 ,132.4 ,0.0 ,192.0 ,0.0 ,978.4 ,825.5 ,28 ,28.02 \\r\\n427.5 ,47.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,270 ,43.01 \\r\\n190.0 ,190.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,90 ,42.33 \\r\\n304.0 ,76.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,28 ,47.81 \\r\\n380.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,90 ,52.91 \\r\\n139.6 ,209.4 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.9 ,90 ,39.36 \\r\\n342.0 ,38.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,365 ,56.14 \\r\\n380.0 ,95.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,90 ,40.56 \\r\\n475.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,180 ,42.62 \\r\\n427.5 ,47.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,180 ,41.84 \\r\\n139.6 ,209.4 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.9 ,28 ,28.24 \\r\\n139.6 ,209.4 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.9 ,3 ,8.06 \\r\\n139.6 ,209.4 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.9 ,180 ,44.21 \\r\\n380.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,365 ,52.52 \\r\\n380.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,270 ,53.30 \\r\\n380.0 ,95.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,270 ,41.15 \\r\\n342.0 ,38.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,180 ,52.12 \\r\\n427.5 ,47.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,28 ,37.43 \\r\\n475.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,7 ,38.60 \\r\\n304.0 ,76.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,365 ,55.26 \\r\\n266.0 ,114.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,365 ,52.91 \\r\\n198.6 ,132.4 ,0.0 ,192.0 ,0.0 ,978.4 ,825.5 ,180 ,41.72 \\r\\n475.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,270 ,42.13 \\r\\n190.0 ,190.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,365 ,53.69 \\r\\n237.5 ,237.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,270 ,38.41 \\r\\n237.5 ,237.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,28 ,30.08 \\r\\n332.5 ,142.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,90 ,37.72 \\r\\n475.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,90 ,42.23 \\r\\n237.5 ,237.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,180 ,36.25 \\r\\n342.0 ,38.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,90 ,50.46 \\r\\n427.5 ,47.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,365 ,43.70 \\r\\n237.5 ,237.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,365 ,39.00 \\r\\n380.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,180 ,53.10 \\r\\n427.5 ,47.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,90 ,41.54 \\r\\n427.5 ,47.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,7 ,35.08 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.9 ,3 ,15.05 \\r\\n380.0 ,95.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,180 ,40.76 \\r\\n237.5 ,237.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,7 ,26.26 \\r\\n380.0 ,95.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,7 ,32.82 \\r\\n332.5 ,142.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,180 ,39.78 \\r\\n190.0 ,190.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,180 ,46.93 \\r\\n237.5 ,237.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,90 ,33.12 \\r\\n304.0 ,76.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,90 ,49.19 \\r\\n139.6 ,209.4 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.9 ,7 ,14.59 \\r\\n198.6 ,132.4 ,0.0 ,192.0 ,0.0 ,978.4 ,825.5 ,7 ,14.64 \\r\\n475.0 ,0.0 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,365 ,41.93 \\r\\n198.6 ,132.4 ,0.0 ,192.0 ,0.0 ,978.4 ,825.5 ,3 ,9.13 \\r\\n304.0 ,76.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,180 ,50.95 \\r\\n332.5 ,142.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,28 ,33.02 \\r\\n304.0 ,76.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,270 ,54.38 \\r\\n266.0 ,114.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,270 ,51.73 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,971.0 ,850.6 ,3 ,9.87 \\r\\n190.0 ,190.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,270 ,50.66 \\r\\n266.0 ,114.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,180 ,48.70 \\r\\n342.0 ,38.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,270 ,55.06 \\r\\n139.6 ,209.4 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.9 ,360 ,44.70 \\r\\n332.5 ,142.5 ,0.0 ,228.0 ,0.0 ,932.0 ,594.0 ,7 ,30.28 \\r\\n190.0 ,190.0 ,0.0 ,228.0 ,0.0 ,932.0 ,670.0 ,28 ,40.86 \\r\\n485.0 ,0.0 ,0.0 ,146.0 ,0.0 ,1120.0 ,800.0 ,28 ,71.99 \\r\\n374.0 ,189.2 ,0.0 ,170.1 ,10.1 ,926.1 ,756.7 ,3 ,34.40 \\r\\n313.3 ,262.2 ,0.0 ,175.5 ,8.6 ,1046.9 ,611.8 ,3 ,28.80 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,3 ,33.40 \\r\\n425.0 ,106.3 ,0.0 ,151.4 ,18.6 ,936.0 ,803.7 ,3 ,36.30 \\r\\n375.0 ,93.8 ,0.0 ,126.6 ,23.4 ,852.1 ,992.6 ,3 ,29.00 \\r\\n475.0 ,118.8 ,0.0 ,181.1 ,8.9 ,852.1 ,781.5 ,3 ,37.80 \\r\\n469.0 ,117.2 ,0.0 ,137.8 ,32.2 ,852.1 ,840.5 ,3 ,40.20 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,3 ,33.40 \\r\\n388.6 ,97.1 ,0.0 ,157.9 ,12.1 ,852.1 ,925.7 ,3 ,28.10 \\r\\n531.3 ,0.0 ,0.0 ,141.8 ,28.2 ,852.1 ,893.7 ,3 ,41.30 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,3 ,33.40 \\r\\n318.8 ,212.5 ,0.0 ,155.7 ,14.3 ,852.1 ,880.4 ,3 ,25.20 \\r\\n401.8 ,94.7 ,0.0 ,147.4 ,11.4 ,946.8 ,852.1 ,3 ,41.10 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,3 ,35.30 \\r\\n323.7 ,282.8 ,0.0 ,183.8 ,10.3 ,942.7 ,659.9 ,3 ,28.30 \\r\\n379.5 ,151.2 ,0.0 ,153.9 ,15.9 ,1134.3 ,605.0 ,3 ,28.60 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,3 ,35.30 \\r\\n286.3 ,200.9 ,0.0 ,144.7 ,11.2 ,1004.6 ,803.7 ,3 ,24.40 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,3 ,35.30 \\r\\n439.0 ,177.0 ,0.0 ,186.0 ,11.1 ,884.9 ,707.9 ,3 ,39.30 \\r\\n389.9 ,189.0 ,0.0 ,145.9 ,22.0 ,944.7 ,755.8 ,3 ,40.60 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,3 ,35.30 \\r\\n337.9 ,189.0 ,0.0 ,174.9 ,9.5 ,944.7 ,755.8 ,3 ,24.10 \\r\\n374.0 ,189.2 ,0.0 ,170.1 ,10.1 ,926.1 ,756.7 ,7 ,46.20 \\r\\n313.3 ,262.2 ,0.0 ,175.5 ,8.6 ,1046.9 ,611.8 ,7 ,42.80 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,7 ,49.20 \\r\\n425.0 ,106.3 ,0.0 ,151.4 ,18.6 ,936.0 ,803.7 ,7 ,46.80 \\r\\n375.0 ,93.8 ,0.0 ,126.6 ,23.4 ,852.1 ,992.6 ,7 ,45.70 \\r\\n475.0 ,118.8 ,0.0 ,181.1 ,8.9 ,852.1 ,781.5 ,7 ,55.60 \\r\\n469.0 ,117.2 ,0.0 ,137.8 ,32.2 ,852.1 ,840.5 ,7 ,54.90 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,7 ,49.20 \\r\\n388.6 ,97.1 ,0.0 ,157.9 ,12.1 ,852.1 ,925.7 ,7 ,34.90 \\r\\n531.3 ,0.0 ,0.0 ,141.8 ,28.2 ,852.1 ,893.7 ,7 ,46.90 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,7 ,49.20 \\r\\n318.8 ,212.5 ,0.0 ,155.7 ,14.3 ,852.1 ,880.4 ,7 ,33.40 \\r\\n401.8 ,94.7 ,0.0 ,147.4 ,11.4 ,946.8 ,852.1 ,7 ,54.10 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,7 ,55.90 \\r\\n323.7 ,282.8 ,0.0 ,183.8 ,10.3 ,942.7 ,659.9 ,7 ,49.80 \\r\\n379.5 ,151.2 ,0.0 ,153.9 ,15.9 ,1134.3 ,605.0 ,7 ,47.10 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,7 ,55.90 \\r\\n286.3 ,200.9 ,0.0 ,144.7 ,11.2 ,1004.6 ,803.7 ,7 ,38.00 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,7 ,55.90 \\r\\n439.0 ,177.0 ,0.0 ,186.0 ,11.1 ,884.9 ,707.9 ,7 ,56.10 \\r\\n389.9 ,189.0 ,0.0 ,145.9 ,22.0 ,944.7 ,755.8 ,7 ,59.09 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,7 ,22.90 \\r\\n337.9 ,189.0 ,0.0 ,174.9 ,9.5 ,944.7 ,755.8 ,7 ,35.10 \\r\\n374.0 ,189.2 ,0.0 ,170.1 ,10.1 ,926.1 ,756.7 ,28 ,61.09 \\r\\n313.3 ,262.2 ,0.0 ,175.5 ,8.6 ,1046.9 ,611.8 ,28 ,59.80 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,28 ,60.29 \\r\\n425.0 ,106.3 ,0.0 ,151.4 ,18.6 ,936.0 ,803.7 ,28 ,61.80 \\r\\n375.0 ,93.8 ,0.0 ,126.6 ,23.4 ,852.1 ,992.6 ,28 ,56.70 \\r\\n475.0 ,118.8 ,0.0 ,181.1 ,8.9 ,852.1 ,781.5 ,28 ,68.30 \\r\\n469.0 ,117.2 ,0.0 ,137.8 ,32.2 ,852.1 ,840.5 ,28 ,66.90 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,28 ,60.29 \\r\\n388.6 ,97.1 ,0.0 ,157.9 ,12.1 ,852.1 ,925.7 ,28 ,50.70 \\r\\n531.3 ,0.0 ,0.0 ,141.8 ,28.2 ,852.1 ,893.7 ,28 ,56.40 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,28 ,60.29 \\r\\n318.8 ,212.5 ,0.0 ,155.7 ,14.3 ,852.1 ,880.4 ,28 ,55.50 \\r\\n401.8 ,94.7 ,0.0 ,147.4 ,11.4 ,946.8 ,852.1 ,28 ,68.50 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,28 ,71.30 \\r\\n323.7 ,282.8 ,0.0 ,183.8 ,10.3 ,942.7 ,659.9 ,28 ,74.70 \\r\\n379.5 ,151.2 ,0.0 ,153.9 ,15.9 ,1134.3 ,605.0 ,28 ,52.20 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,28 ,71.30 \\r\\n286.3 ,200.9 ,0.0 ,144.7 ,11.2 ,1004.6 ,803.7 ,28 ,67.70 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,28 ,71.30 \\r\\n439.0 ,177.0 ,0.0 ,186.0 ,11.1 ,884.9 ,707.9 ,28 ,66.00 \\r\\n389.9 ,189.0 ,0.0 ,145.9 ,22.0 ,944.7 ,755.8 ,28 ,74.50 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,28 ,71.30 \\r\\n337.9 ,189.0 ,0.0 ,174.9 ,9.5 ,944.7 ,755.8 ,28 ,49.90 \\r\\n374.0 ,189.2 ,0.0 ,170.1 ,10.1 ,926.1 ,756.7 ,56 ,63.40 \\r\\n313.3 ,262.2 ,0.0 ,175.5 ,8.6 ,1046.9 ,611.8 ,56 ,64.90 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,56 ,64.30 \\r\\n425.0 ,106.3 ,0.0 ,151.4 ,18.6 ,936.0 ,803.7 ,56 ,64.90 \\r\\n375.0 ,93.8 ,0.0 ,126.6 ,23.4 ,852.1 ,992.6 ,56 ,60.20 \\r\\n475.0 ,118.8 ,0.0 ,181.1 ,8.9 ,852.1 ,781.5 ,56 ,72.30 \\r\\n469.0 ,117.2 ,0.0 ,137.8 ,32.2 ,852.1 ,840.5 ,56 ,69.30 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,56 ,64.30 \\r\\n388.6 ,97.1 ,0.0 ,157.9 ,12.1 ,852.1 ,925.7 ,56 ,55.20 \\r\\n531.3 ,0.0 ,0.0 ,141.8 ,28.2 ,852.1 ,893.7 ,56 ,58.80 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,56 ,64.30 \\r\\n318.8 ,212.5 ,0.0 ,155.7 ,14.3 ,852.1 ,880.4 ,56 ,66.10 \\r\\n401.8 ,94.7 ,0.0 ,147.4 ,11.4 ,946.8 ,852.1 ,56 ,73.70 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,56 ,77.30 \\r\\n323.7 ,282.8 ,0.0 ,183.8 ,10.3 ,942.7 ,659.9 ,56 ,80.20 \\r\\n379.5 ,151.2 ,0.0 ,153.9 ,15.9 ,1134.3 ,605.0 ,56 ,54.90 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,56 ,77.30 \\r\\n286.3 ,200.9 ,0.0 ,144.7 ,11.2 ,1004.6 ,803.7 ,56 ,72.99 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,56 ,77.30 \\r\\n439.0 ,177.0 ,0.0 ,186.0 ,11.1 ,884.9 ,707.9 ,56 ,71.70 \\r\\n389.9 ,189.0 ,0.0 ,145.9 ,22.0 ,944.7 ,755.8 ,56 ,79.40 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,56 ,77.30 \\r\\n337.9 ,189.0 ,0.0 ,174.9 ,9.5 ,944.7 ,755.8 ,56 ,59.89 \\r\\n374.0 ,189.2 ,0.0 ,170.1 ,10.1 ,926.1 ,756.7 ,91 ,64.90 \\r\\n313.3 ,262.2 ,0.0 ,175.5 ,8.6 ,1046.9 ,611.8 ,91 ,66.60 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,91 ,65.20 \\r\\n425.0 ,106.3 ,0.0 ,151.4 ,18.6 ,936.0 ,803.7 ,91 ,66.70 \\r\\n375.0 ,93.8 ,0.0 ,126.6 ,23.4 ,852.1 ,992.6 ,91 ,62.50 \\r\\n475.0 ,118.8 ,0.0 ,181.1 ,8.9 ,852.1 ,781.5 ,91 ,74.19 \\r\\n469.0 ,117.2 ,0.0 ,137.8 ,32.2 ,852.1 ,840.5 ,91 ,70.70 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,91 ,65.20 \\r\\n388.6 ,97.1 ,0.0 ,157.9 ,12.1 ,852.1 ,925.7 ,91 ,57.60 \\r\\n531.3 ,0.0 ,0.0 ,141.8 ,28.2 ,852.1 ,893.7 ,91 ,59.20 \\r\\n425.0 ,106.3 ,0.0 ,153.5 ,16.5 ,852.1 ,887.1 ,91 ,65.20 \\r\\n318.8 ,212.5 ,0.0 ,155.7 ,14.3 ,852.1 ,880.4 ,91 ,68.10 \\r\\n401.8 ,94.7 ,0.0 ,147.4 ,11.4 ,946.8 ,852.1 ,91 ,75.50 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,91 ,79.30 \\r\\n379.5 ,151.2 ,0.0 ,153.9 ,15.9 ,1134.3 ,605.0 ,91 ,56.50 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,91 ,79.30 \\r\\n286.3 ,200.9 ,0.0 ,144.7 ,11.2 ,1004.6 ,803.7 ,91 ,76.80 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,91 ,79.30 \\r\\n439.0 ,177.0 ,0.0 ,186.0 ,11.1 ,884.9 ,707.9 ,91 ,73.30 \\r\\n389.9 ,189.0 ,0.0 ,145.9 ,22.0 ,944.7 ,755.8 ,91 ,82.60 \\r\\n362.6 ,189.0 ,0.0 ,164.9 ,11.6 ,944.7 ,755.8 ,91 ,79.30 \\r\\n337.9 ,189.0 ,0.0 ,174.9 ,9.5 ,944.7 ,755.8 ,91 ,67.80 \\r\\n222.4 ,0.0 ,96.7 ,189.3 ,4.5 ,967.1 ,870.3 ,3 ,11.58 \\r\\n222.4 ,0.0 ,96.7 ,189.3 ,4.5 ,967.1 ,870.3 ,14 ,24.45 \\r\\n222.4 ,0.0 ,96.7 ,189.3 ,4.5 ,967.1 ,870.3 ,28 ,24.89 \\r\\n222.4 ,0.0 ,96.7 ,189.3 ,4.5 ,967.1 ,870.3 ,56 ,29.45 \\r\\n222.4 ,0.0 ,96.7 ,189.3 ,4.5 ,967.1 ,870.3 ,100 ,40.71 \\r\\n233.8 ,0.0 ,94.6 ,197.9 ,4.6 ,947.0 ,852.2 ,3 ,10.38 \\r\\n233.8 ,0.0 ,94.6 ,197.9 ,4.6 ,947.0 ,852.2 ,14 ,22.14 \\r\\n233.8 ,0.0 ,94.6 ,197.9 ,4.6 ,947.0 ,852.2 ,28 ,22.84 \\r\\n233.8 ,0.0 ,94.6 ,197.9 ,4.6 ,947.0 ,852.2 ,56 ,27.66 \\r\\n233.8 ,0.0 ,94.6 ,197.9 ,4.6 ,947.0 ,852.2 ,100 ,34.56 \\r\\n194.7 ,0.0 ,100.5 ,165.6 ,7.5 ,1006.4 ,905.9 ,3 ,12.45 \\r\\n194.7 ,0.0 ,100.5 ,165.6 ,7.5 ,1006.4 ,905.9 ,14 ,24.99 \\r\\n194.7 ,0.0 ,100.5 ,165.6 ,7.5 ,1006.4 ,905.9 ,28 ,25.72 \\r\\n194.7 ,0.0 ,100.5 ,165.6 ,7.5 ,1006.4 ,905.9 ,56 ,33.96 \\r\\n194.7 ,0.0 ,100.5 ,165.6 ,7.5 ,1006.4 ,905.9 ,100 ,37.34 \\r\\n190.7 ,0.0 ,125.4 ,162.1 ,7.8 ,1090.0 ,804.0 ,3 ,15.04 \\r\\n190.7 ,0.0 ,125.4 ,162.1 ,7.8 ,1090.0 ,804.0 ,14 ,21.06 \\r\\n190.7 ,0.0 ,125.4 ,162.1 ,7.8 ,1090.0 ,804.0 ,28 ,26.40 \\r\\n190.7 ,0.0 ,125.4 ,162.1 ,7.8 ,1090.0 ,804.0 ,56 ,35.34 \\r\\n190.7 ,0.0 ,125.4 ,162.1 ,7.8 ,1090.0 ,804.0 ,100 ,40.57 \\r\\n212.1 ,0.0 ,121.6 ,180.3 ,5.7 ,1057.6 ,779.3 ,3 ,12.47 \\r\\n212.1 ,0.0 ,121.6 ,180.3 ,5.7 ,1057.6 ,779.3 ,14 ,20.92 \\r\\n212.1 ,0.0 ,121.6 ,180.3 ,5.7 ,1057.6 ,779.3 ,28 ,24.90 \\r\\n212.1 ,0.0 ,121.6 ,180.3 ,5.7 ,1057.6 ,779.3 ,56 ,34.20 \\r\\n212.1 ,0.0 ,121.6 ,180.3 ,5.7 ,1057.6 ,779.3 ,100 ,39.61 \\r\\n230.0 ,0.0 ,118.3 ,195.5 ,4.6 ,1029.4 ,758.6 ,3 ,10.03 \\r\\n230.0 ,0.0 ,118.3 ,195.5 ,4.6 ,1029.4 ,758.6 ,14 ,20.08 \\r\\n230.0 ,0.0 ,118.3 ,195.5 ,4.6 ,1029.4 ,758.6 ,28 ,24.48 \\r\\n230.0 ,0.0 ,118.3 ,195.5 ,4.6 ,1029.4 ,758.6 ,56 ,31.54 \\r\\n230.0 ,0.0 ,118.3 ,195.5 ,4.6 ,1029.4 ,758.6 ,100 ,35.34 \\r\\n190.3 ,0.0 ,125.2 ,161.9 ,9.9 ,1088.1 ,802.6 ,3 ,9.45 \\r\\n190.3 ,0.0 ,125.2 ,161.9 ,9.9 ,1088.1 ,802.6 ,14 ,22.72 \\r\\n190.3 ,0.0 ,125.2 ,161.9 ,9.9 ,1088.1 ,802.6 ,28 ,28.47 \\r\\n190.3 ,0.0 ,125.2 ,161.9 ,9.9 ,1088.1 ,802.6 ,56 ,38.56 \\r\\n190.3 ,0.0 ,125.2 ,161.9 ,9.9 ,1088.1 ,802.6 ,100 ,40.39 \\r\\n166.1 ,0.0 ,163.3 ,176.5 ,4.5 ,1058.6 ,780.1 ,3 ,10.76 \\r\\n166.1 ,0.0 ,163.3 ,176.5 ,4.5 ,1058.6 ,780.1 ,14 ,25.48 \\r\\n166.1 ,0.0 ,163.3 ,176.5 ,4.5 ,1058.6 ,780.1 ,28 ,21.54 \\r\\n166.1 ,0.0 ,163.3 ,176.5 ,4.5 ,1058.6 ,780.1 ,56 ,28.63 \\r\\n166.1 ,0.0 ,163.3 ,176.5 ,4.5 ,1058.6 ,780.1 ,100 ,33.54 \\r\\n168.0 ,42.1 ,163.8 ,121.8 ,5.7 ,1058.7 ,780.1 ,3 ,7.75 \\r\\n168.0 ,42.1 ,163.8 ,121.8 ,5.7 ,1058.7 ,780.1 ,14 ,17.82 \\r\\n168.0 ,42.1 ,163.8 ,121.8 ,5.7 ,1058.7 ,780.1 ,28 ,24.24 \\r\\n168.0 ,42.1 ,163.8 ,121.8 ,5.7 ,1058.7 ,780.1 ,56 ,32.85 \\r\\n168.0 ,42.1 ,163.8 ,121.8 ,5.7 ,1058.7 ,780.1 ,100 ,39.23 \\r\\n213.7 ,98.1 ,24.5 ,181.7 ,6.9 ,1065.8 ,785.4 ,3 ,18.00 \\r\\n213.7 ,98.1 ,24.5 ,181.7 ,6.9 ,1065.8 ,785.4 ,14 ,30.39 \\r\\n213.7 ,98.1 ,24.5 ,181.7 ,6.9 ,1065.8 ,785.4 ,28 ,45.71 \\r\\n213.7 ,98.1 ,24.5 ,181.7 ,6.9 ,1065.8 ,785.4 ,56 ,50.77 \\r\\n213.7 ,98.1 ,24.5 ,181.7 ,6.9 ,1065.8 ,785.4 ,100 ,53.90 \\r\\n213.8 ,98.1 ,24.5 ,181.7 ,6.7 ,1066.0 ,785.5 ,3 ,13.18 \\r\\n213.8 ,98.1 ,24.5 ,181.7 ,6.7 ,1066.0 ,785.5 ,14 ,17.84 \\r\\n213.8 ,98.1 ,24.5 ,181.7 ,6.7 ,1066.0 ,785.5 ,28 ,40.23 \\r\\n213.8 ,98.1 ,24.5 ,181.7 ,6.7 ,1066.0 ,785.5 ,56 ,47.13 \\r\\n213.8 ,98.1 ,24.5 ,181.7 ,6.7 ,1066.0 ,785.5 ,100 ,49.97 \\r\\n229.7 ,0.0 ,118.2 ,195.2 ,6.1 ,1028.1 ,757.6 ,3 ,13.36 \\r\\n229.7 ,0.0 ,118.2 ,195.2 ,6.1 ,1028.1 ,757.6 ,14 ,22.32 \\r\\n229.7 ,0.0 ,118.2 ,195.2 ,6.1 ,1028.1 ,757.6 ,28 ,24.54 \\r\\n229.7 ,0.0 ,118.2 ,195.2 ,6.1 ,1028.1 ,757.6 ,56 ,31.35 \\r\\n229.7 ,0.0 ,118.2 ,195.2 ,6.1 ,1028.1 ,757.6 ,100 ,40.86 \\r\\n238.1 ,0.0 ,94.1 ,186.7 ,7.0 ,949.9 ,847.0 ,3 ,19.93 \\r\\n238.1 ,0.0 ,94.1 ,186.7 ,7.0 ,949.9 ,847.0 ,14 ,25.69 \\r\\n238.1 ,0.0 ,94.1 ,186.7 ,7.0 ,949.9 ,847.0 ,28 ,30.23 \\r\\n238.1 ,0.0 ,94.1 ,186.7 ,7.0 ,949.9 ,847.0 ,56 ,39.59 \\r\\n238.1 ,0.0 ,94.1 ,186.7 ,7.0 ,949.9 ,847.0 ,100 ,44.30 \\r\\n250.0 ,0.0 ,95.7 ,187.4 ,5.5 ,956.9 ,861.2 ,3 ,13.82 \\r\\n250.0 ,0.0 ,95.7 ,187.4 ,5.5 ,956.9 ,861.2 ,14 ,24.92 \\r\\n250.0 ,0.0 ,95.7 ,187.4 ,5.5 ,956.9 ,861.2 ,28 ,29.22 \\r\\n250.0 ,0.0 ,95.7 ,187.4 ,5.5 ,956.9 ,861.2 ,56 ,38.33 \\r\\n250.0 ,0.0 ,95.7 ,187.4 ,5.5 ,956.9 ,861.2 ,100 ,42.35 \\r\\n212.5 ,0.0 ,100.4 ,159.3 ,8.7 ,1007.8 ,903.6 ,3 ,13.54 \\r\\n212.5 ,0.0 ,100.4 ,159.3 ,8.7 ,1007.8 ,903.6 ,14 ,26.31 \\r\\n212.5 ,0.0 ,100.4 ,159.3 ,8.7 ,1007.8 ,903.6 ,28 ,31.64 \\r\\n212.5 ,0.0 ,100.4 ,159.3 ,8.7 ,1007.8 ,903.6 ,56 ,42.55 \\r\\n212.5 ,0.0 ,100.4 ,159.3 ,8.7 ,1007.8 ,903.6 ,100 ,42.92 \\r\\n212.6 ,0.0 ,100.4 ,159.4 ,10.4 ,1003.8 ,903.8 ,3 ,13.33 \\r\\n212.6 ,0.0 ,100.4 ,159.4 ,10.4 ,1003.8 ,903.8 ,14 ,25.37 \\r\\n212.6 ,0.0 ,100.4 ,159.4 ,10.4 ,1003.8 ,903.8 ,28 ,37.40 \\r\\n212.6 ,0.0 ,100.4 ,159.4 ,10.4 ,1003.8 ,903.8 ,56 ,44.40 \\r\\n212.6 ,0.0 ,100.4 ,159.4 ,10.4 ,1003.8 ,903.8 ,100 ,47.74 \\r\\n212.0 ,0.0 ,124.8 ,159.0 ,7.8 ,1085.4 ,799.5 ,3 ,19.52 \\r\\n212.0 ,0.0 ,124.8 ,159.0 ,7.8 ,1085.4 ,799.5 ,14 ,31.35 \\r\\n212.0 ,0.0 ,124.8 ,159.0 ,7.8 ,1085.4 ,799.5 ,28 ,38.50 \\r\\n212.0 ,0.0 ,124.8 ,159.0 ,7.8 ,1085.4 ,799.5 ,56 ,45.08 \\r\\n212.0 ,0.0 ,124.8 ,159.0 ,7.8 ,1085.4 ,799.5 ,100 ,47.82 \\r\\n231.8 ,0.0 ,121.6 ,174.0 ,6.7 ,1056.4 ,778.5 ,3 ,15.44 \\r\\n231.8 ,0.0 ,121.6 ,174.0 ,6.7 ,1056.4 ,778.5 ,14 ,26.77 \\r\\n231.8 ,0.0 ,121.6 ,174.0 ,6.7 ,1056.4 ,778.5 ,28 ,33.73 \\r\\n231.8 ,0.0 ,121.6 ,174.0 ,6.7 ,1056.4 ,778.5 ,56 ,42.70 \\r\\n231.8 ,0.0 ,121.6 ,174.0 ,6.7 ,1056.4 ,778.5 ,100 ,45.84 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,5.8 ,1028.4 ,757.7 ,3 ,17.22 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,5.8 ,1028.4 ,757.7 ,14 ,29.93 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,5.8 ,1028.4 ,757.7 ,28 ,29.65 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,5.8 ,1028.4 ,757.7 ,56 ,36.97 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,5.8 ,1028.4 ,757.7 ,100 ,43.58 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,6.4 ,1028.4 ,757.7 ,3 ,13.12 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,6.4 ,1028.4 ,757.7 ,14 ,24.43 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,6.4 ,1028.4 ,757.7 ,28 ,32.66 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,6.4 ,1028.4 ,757.7 ,56 ,36.64 \\r\\n251.4 ,0.0 ,118.3 ,188.5 ,6.4 ,1028.4 ,757.7 ,100 ,44.21 \\r\\n181.4 ,0.0 ,167.0 ,169.6 ,7.6 ,1055.6 ,777.8 ,3 ,13.62 \\r\\n181.4 ,0.0 ,167.0 ,169.6 ,7.6 ,1055.6 ,777.8 ,14 ,21.60 \\r\\n181.4 ,0.0 ,167.0 ,169.6 ,7.6 ,1055.6 ,777.8 ,28 ,27.77 \\r\\n181.4 ,0.0 ,167.0 ,169.6 ,7.6 ,1055.6 ,777.8 ,56 ,35.57 \\r\\n181.4 ,0.0 ,167.0 ,169.6 ,7.6 ,1055.6 ,777.8 ,100 ,45.37 \\r\\n182.0 ,45.2 ,122.0 ,170.2 ,8.2 ,1059.4 ,780.7 ,3 ,7.32 \\r\\n182.0 ,45.2 ,122.0 ,170.2 ,8.2 ,1059.4 ,780.7 ,14 ,21.50 \\r\\n182.0 ,45.2 ,122.0 ,170.2 ,8.2 ,1059.4 ,780.7 ,28 ,31.27 \\r\\n182.0 ,45.2 ,122.0 ,170.2 ,8.2 ,1059.4 ,780.7 ,56 ,43.50 \\r\\n182.0 ,45.2 ,122.0 ,170.2 ,8.2 ,1059.4 ,780.7 ,100 ,48.67 \\r\\n168.9 ,42.2 ,124.3 ,158.3 ,10.8 ,1080.8 ,796.2 ,3 ,7.40 \\r\\n168.9 ,42.2 ,124.3 ,158.3 ,10.8 ,1080.8 ,796.2 ,14 ,23.51 \\r\\n168.9 ,42.2 ,124.3 ,158.3 ,10.8 ,1080.8 ,796.2 ,28 ,31.12 \\r\\n168.9 ,42.2 ,124.3 ,158.3 ,10.8 ,1080.8 ,796.2 ,56 ,39.15 \\r\\n168.9 ,42.2 ,124.3 ,158.3 ,10.8 ,1080.8 ,796.2 ,100 ,48.15 \\r\\n290.4 ,0.0 ,96.2 ,168.1 ,9.4 ,961.2 ,865.0 ,3 ,22.50 \\r\\n290.4 ,0.0 ,96.2 ,168.1 ,9.4 ,961.2 ,865.0 ,14 ,34.67 \\r\\n290.4 ,0.0 ,96.2 ,168.1 ,9.4 ,961.2 ,865.0 ,28 ,34.74 \\r\\n290.4 ,0.0 ,96.2 ,168.1 ,9.4 ,961.2 ,865.0 ,56 ,45.08 \\r\\n290.4 ,0.0 ,96.2 ,168.1 ,9.4 ,961.2 ,865.0 ,100 ,48.97 \\r\\n277.1 ,0.0 ,97.4 ,160.6 ,11.8 ,973.9 ,875.6 ,3 ,23.14 \\r\\n277.1 ,0.0 ,97.4 ,160.6 ,11.8 ,973.9 ,875.6 ,14 ,41.89 \\r\\n277.1 ,0.0 ,97.4 ,160.6 ,11.8 ,973.9 ,875.6 ,28 ,48.28 \\r\\n277.1 ,0.0 ,97.4 ,160.6 ,11.8 ,973.9 ,875.6 ,56 ,51.04 \\r\\n277.1 ,0.0 ,97.4 ,160.6 ,11.8 ,973.9 ,875.6 ,100 ,55.64 \\r\\n295.7 ,0.0 ,95.6 ,171.5 ,8.9 ,955.1 ,859.2 ,3 ,22.95 \\r\\n295.7 ,0.0 ,95.6 ,171.5 ,8.9 ,955.1 ,859.2 ,14 ,35.23 \\r\\n295.7 ,0.0 ,95.6 ,171.5 ,8.9 ,955.1 ,859.2 ,28 ,39.94 \\r\\n295.7 ,0.0 ,95.6 ,171.5 ,8.9 ,955.1 ,859.2 ,56 ,48.72 \\r\\n295.7 ,0.0 ,95.6 ,171.5 ,8.9 ,955.1 ,859.2 ,100 ,52.04 \\r\\n251.8 ,0.0 ,99.9 ,146.1 ,12.4 ,1006.0 ,899.8 ,3 ,21.02 \\r\\n251.8 ,0.0 ,99.9 ,146.1 ,12.4 ,1006.0 ,899.8 ,14 ,33.36 \\r\\n251.8 ,0.0 ,99.9 ,146.1 ,12.4 ,1006.0 ,899.8 ,28 ,33.94 \\r\\n251.8 ,0.0 ,99.9 ,146.1 ,12.4 ,1006.0 ,899.8 ,56 ,44.14 \\r\\n251.8 ,0.0 ,99.9 ,146.1 ,12.4 ,1006.0 ,899.8 ,100 ,45.37 \\r\\n249.1 ,0.0 ,98.8 ,158.1 ,12.8 ,987.8 ,889.0 ,3 ,15.36 \\r\\n249.1 ,0.0 ,98.8 ,158.1 ,12.8 ,987.8 ,889.0 ,14 ,28.68 \\r\\n249.1 ,0.0 ,98.8 ,158.1 ,12.8 ,987.8 ,889.0 ,28 ,30.85 \\r\\n249.1 ,0.0 ,98.8 ,158.1 ,12.8 ,987.8 ,889.0 ,56 ,42.03 \\r\\n249.1 ,0.0 ,98.8 ,158.1 ,12.8 ,987.8 ,889.0 ,100 ,51.06 \\r\\n252.3 ,0.0 ,98.8 ,146.3 ,14.2 ,987.8 ,889.0 ,3 ,21.78 \\r\\n252.3 ,0.0 ,98.8 ,146.3 ,14.2 ,987.8 ,889.0 ,14 ,42.29 \\r\\n252.3 ,0.0 ,98.8 ,146.3 ,14.2 ,987.8 ,889.0 ,28 ,50.60 \\r\\n252.3 ,0.0 ,98.8 ,146.3 ,14.2 ,987.8 ,889.0 ,56 ,55.83 \\r\\n252.3 ,0.0 ,98.8 ,146.3 ,14.2 ,987.8 ,889.0 ,100 ,60.95 \\r\\n246.8 ,0.0 ,125.1 ,143.3 ,12.0 ,1086.8 ,800.9 ,3 ,23.52 \\r\\n246.8 ,0.0 ,125.1 ,143.3 ,12.0 ,1086.8 ,800.9 ,14 ,42.22 \\r\\n246.8 ,0.0 ,125.1 ,143.3 ,12.0 ,1086.8 ,800.9 ,28 ,52.50 \\r\\n246.8 ,0.0 ,125.1 ,143.3 ,12.0 ,1086.8 ,800.9 ,56 ,60.32 \\r\\n246.8 ,0.0 ,125.1 ,143.3 ,12.0 ,1086.8 ,800.9 ,100 ,66.42 \\r\\n275.1 ,0.0 ,121.4 ,159.5 ,9.9 ,1053.6 ,777.5 ,3 ,23.80 \\r\\n275.1 ,0.0 ,121.4 ,159.5 ,9.9 ,1053.6 ,777.5 ,14 ,38.77 \\r\\n275.1 ,0.0 ,121.4 ,159.5 ,9.9 ,1053.6 ,777.5 ,28 ,51.33 \\r\\n275.1 ,0.0 ,121.4 ,159.5 ,9.9 ,1053.6 ,777.5 ,56 ,56.85 \\r\\n275.1 ,0.0 ,121.4 ,159.5 ,9.9 ,1053.6 ,777.5 ,100 ,58.61 \\r\\n297.2 ,0.0 ,117.5 ,174.8 ,9.5 ,1022.8 ,753.5 ,3 ,21.91 \\r\\n297.2 ,0.0 ,117.5 ,174.8 ,9.5 ,1022.8 ,753.5 ,14 ,36.99 \\r\\n297.2 ,0.0 ,117.5 ,174.8 ,9.5 ,1022.8 ,753.5 ,28 ,47.40 \\r\\n297.2 ,0.0 ,117.5 ,174.8 ,9.5 ,1022.8 ,753.5 ,56 ,51.96 \\r\\n297.2 ,0.0 ,117.5 ,174.8 ,9.5 ,1022.8 ,753.5 ,100 ,56.74 \\r\\n213.7 ,0.0 ,174.7 ,154.8 ,10.2 ,1053.5 ,776.4 ,3 ,17.57 \\r\\n213.7 ,0.0 ,174.7 ,154.8 ,10.2 ,1053.5 ,776.4 ,14 ,33.73 \\r\\n213.7 ,0.0 ,174.7 ,154.8 ,10.2 ,1053.5 ,776.4 ,28 ,40.15 \\r\\n213.7 ,0.0 ,174.7 ,154.8 ,10.2 ,1053.5 ,776.4 ,56 ,46.64 \\r\\n213.7 ,0.0 ,174.7 ,154.8 ,10.2 ,1053.5 ,776.4 ,100 ,50.08 \\r\\n213.5 ,0.0 ,174.2 ,154.6 ,11.7 ,1052.3 ,775.5 ,3 ,17.37 \\r\\n213.5 ,0.0 ,174.2 ,154.6 ,11.7 ,1052.3 ,775.5 ,14 ,33.70 \\r\\n213.5 ,0.0 ,174.2 ,154.6 ,11.7 ,1052.3 ,775.5 ,28 ,45.94 \\r\\n213.5 ,0.0 ,174.2 ,154.6 ,11.7 ,1052.3 ,775.5 ,56 ,51.43 \\r\\n213.5 ,0.0 ,174.2 ,154.6 ,11.7 ,1052.3 ,775.5 ,100 ,59.30 \\r\\n277.2 ,97.8 ,24.5 ,160.7 ,11.2 ,1061.7 ,782.5 ,3 ,30.45 \\r\\n277.2 ,97.8 ,24.5 ,160.7 ,11.2 ,1061.7 ,782.5 ,14 ,47.71 \\r\\n277.2 ,97.8 ,24.5 ,160.7 ,11.2 ,1061.7 ,782.5 ,28 ,63.14 \\r\\n277.2 ,97.8 ,24.5 ,160.7 ,11.2 ,1061.7 ,782.5 ,56 ,66.82 \\r\\n277.2 ,97.8 ,24.5 ,160.7 ,11.2 ,1061.7 ,782.5 ,100 ,66.95 \\r\\n218.2 ,54.6 ,123.8 ,140.8 ,11.9 ,1075.7 ,792.7 ,3 ,27.42 \\r\\n218.2 ,54.6 ,123.8 ,140.8 ,11.9 ,1075.7 ,792.7 ,14 ,35.96 \\r\\n218.2 ,54.6 ,123.8 ,140.8 ,11.9 ,1075.7 ,792.7 ,28 ,55.51 \\r\\n218.2 ,54.6 ,123.8 ,140.8 ,11.9 ,1075.7 ,792.7 ,56 ,61.99 \\r\\n218.2 ,54.6 ,123.8 ,140.8 ,11.9 ,1075.7 ,792.7 ,100 ,63.53 \\r\\n214.9 ,53.8 ,121.9 ,155.6 ,9.6 ,1014.3 ,780.6 ,3 ,18.02 \\r\\n214.9 ,53.8 ,121.9 ,155.6 ,9.6 ,1014.3 ,780.6 ,14 ,38.60 \\r\\n214.9 ,53.8 ,121.9 ,155.6 ,9.6 ,1014.3 ,780.6 ,28 ,52.20 \\r\\n214.9 ,53.8 ,121.9 ,155.6 ,9.6 ,1014.3 ,780.6 ,56 ,53.96 \\r\\n214.9 ,53.8 ,121.9 ,155.6 ,9.6 ,1014.3 ,780.6 ,100 ,56.63 \\r\\n218.9 ,0.0 ,124.1 ,158.5 ,11.3 ,1078.7 ,794.9 ,3 ,15.34 \\r\\n218.9 ,0.0 ,124.1 ,158.5 ,11.3 ,1078.7 ,794.9 ,14 ,26.05 \\r\\n218.9 ,0.0 ,124.1 ,158.5 ,11.3 ,1078.7 ,794.9 ,28 ,30.22 \\r\\n218.9 ,0.0 ,124.1 ,158.5 ,11.3 ,1078.7 ,794.9 ,56 ,37.27 \\r\\n218.9 ,0.0 ,124.1 ,158.5 ,11.3 ,1078.7 ,794.9 ,100 ,46.23 \\r\\n376.0 ,0.0 ,0.0 ,214.6 ,0.0 ,1003.5 ,762.4 ,3 ,16.28 \\r\\n376.0 ,0.0 ,0.0 ,214.6 ,0.0 ,1003.5 ,762.4 ,14 ,25.62 \\r\\n376.0 ,0.0 ,0.0 ,214.6 ,0.0 ,1003.5 ,762.4 ,28 ,31.97 \\r\\n376.0 ,0.0 ,0.0 ,214.6 ,0.0 ,1003.5 ,762.4 ,56 ,36.30 \\r\\n376.0 ,0.0 ,0.0 ,214.6 ,0.0 ,1003.5 ,762.4 ,100 ,43.06 \\r\\n500.0 ,0.0 ,0.0 ,140.0 ,4.0 ,966.0 ,853.0 ,28 ,67.57 \\r\\n475.0 ,0.0 ,59.0 ,142.0 ,1.9 ,1098.0 ,641.0 ,28 ,57.23 \\r\\n315.0 ,137.0 ,0.0 ,145.0 ,5.9 ,1130.0 ,745.0 ,28 ,81.75 \\r\\n505.0 ,0.0 ,60.0 ,195.0 ,0.0 ,1030.0 ,630.0 ,28 ,64.02 \\r\\n451.0 ,0.0 ,0.0 ,165.0 ,11.3 ,1030.0 ,745.0 ,28 ,78.80 \\r\\n516.0 ,0.0 ,0.0 ,162.0 ,8.2 ,801.0 ,802.0 ,28 ,41.37 \\r\\n520.0 ,0.0 ,0.0 ,170.0 ,5.2 ,855.0 ,855.0 ,28 ,60.28 \\r\\n528.0 ,0.0 ,0.0 ,185.0 ,6.9 ,920.0 ,720.0 ,28 ,56.83 \\r\\n520.0 ,0.0 ,0.0 ,175.0 ,5.2 ,870.0 ,805.0 ,28 ,51.02 \\r\\n385.0 ,0.0 ,136.0 ,158.0 ,20.0 ,903.0 ,768.0 ,28 ,55.55 \\r\\n500.1 ,0.0 ,0.0 ,200.0 ,3.0 ,1124.4 ,613.2 ,28 ,44.13 \\r\\n450.1 ,50.0 ,0.0 ,200.0 ,3.0 ,1124.4 ,613.2 ,28 ,39.38 \\r\\n397.0 ,17.2 ,158.0 ,167.0 ,20.8 ,967.0 ,633.0 ,28 ,55.65 \\r\\n333.0 ,17.5 ,163.0 ,167.0 ,17.9 ,996.0 ,652.0 ,28 ,47.28 \\r\\n334.0 ,17.6 ,158.0 ,189.0 ,15.3 ,967.0 ,633.0 ,28 ,44.33 \\r\\n405.0 ,0.0 ,0.0 ,175.0 ,0.0 ,1120.0 ,695.0 ,28 ,52.30 \\r\\n200.0 ,200.0 ,0.0 ,190.0 ,0.0 ,1145.0 ,660.0 ,28 ,49.25 \\r\\n516.0 ,0.0 ,0.0 ,162.0 ,8.3 ,801.0 ,802.0 ,28 ,41.37 \\r\\n145.0 ,116.0 ,119.0 ,184.0 ,5.7 ,833.0 ,880.0 ,28 ,29.16 \\r\\n160.0 ,128.0 ,122.0 ,182.0 ,6.4 ,824.0 ,879.0 ,28 ,39.40 \\r\\n234.0 ,156.0 ,0.0 ,189.0 ,5.9 ,981.0 ,760.0 ,28 ,39.30 \\r\\n250.0 ,180.0 ,95.0 ,159.0 ,9.5 ,860.0 ,800.0 ,28 ,67.87 \\r\\n475.0 ,0.0 ,0.0 ,162.0 ,9.5 ,1044.0 ,662.0 ,28 ,58.52 \\r\\n285.0 ,190.0 ,0.0 ,163.0 ,7.6 ,1031.0 ,685.0 ,28 ,53.58 \\r\\n356.0 ,119.0 ,0.0 ,160.0 ,9.0 ,1061.0 ,657.0 ,28 ,59.00 \\r\\n275.0 ,180.0 ,120.0 ,162.0 ,10.4 ,830.0 ,765.0 ,28 ,76.24 \\r\\n500.0 ,0.0 ,0.0 ,151.0 ,9.0 ,1033.0 ,655.0 ,28 ,69.84 \\r\\n165.0 ,0.0 ,143.6 ,163.8 ,0.0 ,1005.6 ,900.9 ,3 ,14.40 \\r\\n165.0 ,128.5 ,132.1 ,175.1 ,8.1 ,1005.8 ,746.6 ,3 ,19.42 \\r\\n178.0 ,129.8 ,118.6 ,179.9 ,3.6 ,1007.3 ,746.8 ,3 ,20.73 \\r\\n167.4 ,129.9 ,128.6 ,175.5 ,7.8 ,1006.3 ,746.6 ,3 ,14.94 \\r\\n172.4 ,13.6 ,172.4 ,156.8 ,4.1 ,1006.3 ,856.4 ,3 ,21.29 \\r\\n173.5 ,50.1 ,173.5 ,164.8 ,6.5 ,1006.2 ,793.5 ,3 ,23.08 \\r\\n167.0 ,75.4 ,167.0 ,164.0 ,7.9 ,1007.3 ,770.1 ,3 ,15.52 \\r\\n173.8 ,93.4 ,159.9 ,172.3 ,9.7 ,1007.2 ,746.6 ,3 ,15.82 \\r\\n190.3 ,0.0 ,125.2 ,166.6 ,9.9 ,1079.0 ,798.9 ,3 ,12.55 \\r\\n250.0 ,0.0 ,95.7 ,191.8 ,5.3 ,948.9 ,857.2 ,3 ,8.49 \\r\\n213.5 ,0.0 ,174.2 ,159.2 ,11.7 ,1043.6 ,771.9 ,3 ,15.61 \\r\\n194.7 ,0.0 ,100.5 ,170.2 ,7.5 ,998.0 ,901.8 ,3 ,12.18 \\r\\n251.4 ,0.0 ,118.3 ,192.9 ,5.8 ,1043.6 ,754.3 ,3 ,11.98 \\r\\n165.0 ,0.0 ,143.6 ,163.8 ,0.0 ,1005.6 ,900.9 ,14 ,16.88 \\r\\n165.0 ,128.5 ,132.1 ,175.1 ,8.1 ,1005.8 ,746.6 ,14 ,33.09 \\r\\n178.0 ,129.8 ,118.6 ,179.9 ,3.6 ,1007.3 ,746.8 ,14 ,34.24 \\r\\n167.4 ,129.9 ,128.6 ,175.5 ,7.8 ,1006.3 ,746.6 ,14 ,31.81 \\r\\n172.4 ,13.6 ,172.4 ,156.8 ,4.1 ,1006.3 ,856.4 ,14 ,29.75 \\r\\n173.5 ,50.1 ,173.5 ,164.8 ,6.5 ,1006.2 ,793.5 ,14 ,33.01 \\r\\n167.0 ,75.4 ,167.0 ,164.0 ,7.9 ,1007.3 ,770.1 ,14 ,32.90 \\r\\n173.8 ,93.4 ,159.9 ,172.3 ,9.7 ,1007.2 ,746.6 ,14 ,29.55 \\r\\n190.3 ,0.0 ,125.2 ,166.6 ,9.9 ,1079.0 ,798.9 ,14 ,19.42 \\r\\n250.0 ,0.0 ,95.7 ,191.8 ,5.3 ,948.9 ,857.2 ,14 ,24.66 \\r\\n213.5 ,0.0 ,174.2 ,159.2 ,11.7 ,1043.6 ,771.9 ,14 ,29.59 \\r\\n194.7 ,0.0 ,100.5 ,170.2 ,7.5 ,998.0 ,901.8 ,14 ,24.28 \\r\\n251.4 ,0.0 ,118.3 ,192.9 ,5.8 ,1043.6 ,754.3 ,14 ,20.73 \\r\\n165.0 ,0.0 ,143.6 ,163.8 ,0.0 ,1005.6 ,900.9 ,28 ,26.20 \\r\\n165.0 ,128.5 ,132.1 ,175.1 ,8.1 ,1005.8 ,746.6 ,28 ,46.39 \\r\\n178.0 ,129.8 ,118.6 ,179.9 ,3.6 ,1007.3 ,746.8 ,28 ,39.16 \\r\\n167.4 ,129.9 ,128.6 ,175.5 ,7.8 ,1006.3 ,746.6 ,28 ,41.20 \\r\\n172.4 ,13.6 ,172.4 ,156.8 ,4.1 ,1006.3 ,856.4 ,28 ,33.69 \\r\\n173.5 ,50.1 ,173.5 ,164.8 ,6.5 ,1006.2 ,793.5 ,28 ,38.20 \\r\\n167.0 ,75.4 ,167.0 ,164.0 ,7.9 ,1007.3 ,770.1 ,28 ,41.41 \\r\\n173.8 ,93.4 ,159.9 ,172.3 ,9.7 ,1007.2 ,746.6 ,28 ,37.81 \\r\\n190.3 ,0.0 ,125.2 ,166.6 ,9.9 ,1079.0 ,798.9 ,28 ,24.85 \\r\\n250.0 ,0.0 ,95.7 ,191.8 ,5.3 ,948.9 ,857.2 ,28 ,27.22 \\r\\n213.5 ,0.0 ,174.2 ,159.2 ,11.7 ,1043.6 ,771.9 ,28 ,44.64 \\r\\n194.7 ,0.0 ,100.5 ,170.2 ,7.5 ,998.0 ,901.8 ,28 ,37.27 \\r\\n251.4 ,0.0 ,118.3 ,192.9 ,5.8 ,1043.6 ,754.3 ,28 ,33.27 \\r\\n165.0 ,0.0 ,143.6 ,163.8 ,0.0 ,1005.6 ,900.9 ,56 ,36.56 \\r\\n165.0 ,128.5 ,132.1 ,175.1 ,8.1 ,1005.8 ,746.6 ,56 ,53.72 \\r\\n178.0 ,129.8 ,118.6 ,179.9 ,3.6 ,1007.3 ,746.8 ,56 ,48.59 \\r\\n167.4 ,129.9 ,128.6 ,175.5 ,7.8 ,1006.3 ,746.6 ,56 ,51.72 \\r\\n172.4 ,13.6 ,172.4 ,156.8 ,4.1 ,1006.3 ,856.4 ,56 ,35.85 \\r\\n173.5 ,50.1 ,173.5 ,164.8 ,6.5 ,1006.2 ,793.5 ,56 ,53.77 \\r\\n167.0 ,75.4 ,167.0 ,164.0 ,7.9 ,1007.3 ,770.1 ,56 ,53.46 \\r\\n173.8 ,93.4 ,159.9 ,172.3 ,9.7 ,1007.2 ,746.6 ,56 ,48.99 \\r\\n190.3 ,0.0 ,125.2 ,166.6 ,9.9 ,1079.0 ,798.9 ,56 ,31.72 \\r\\n250.0 ,0.0 ,95.7 ,191.8 ,5.3 ,948.9 ,857.2 ,56 ,39.64 \\r\\n213.5 ,0.0 ,174.2 ,159.2 ,11.7 ,1043.6 ,771.9 ,56 ,51.26 \\r\\n194.7 ,0.0 ,100.5 ,170.2 ,7.5 ,998.0 ,901.8 ,56 ,43.39 \\r\\n251.4 ,0.0 ,118.3 ,192.9 ,5.8 ,1043.6 ,754.3 ,56 ,39.27 \\r\\n165.0 ,0.0 ,143.6 ,163.8 ,0.0 ,1005.6 ,900.9 ,100 ,37.96 \\r\\n165.0 ,128.5 ,132.1 ,175.1 ,8.1 ,1005.8 ,746.6 ,100 ,55.02 \\r\\n178.0 ,129.8 ,118.6 ,179.9 ,3.6 ,1007.3 ,746.8 ,100 ,49.99 \\r\\n167.4 ,129.9 ,128.6 ,175.5 ,7.8 ,1006.3 ,746.6 ,100 ,53.66 \\r\\n172.4 ,13.6 ,172.4 ,156.8 ,4.1 ,1006.3 ,856.4 ,100 ,37.68 \\r\\n173.5 ,50.1 ,173.5 ,164.8 ,6.5 ,1006.2 ,793.5 ,100 ,56.06 \\r\\n167.0 ,75.4 ,167.0 ,164.0 ,7.9 ,1007.3 ,770.1 ,100 ,56.81 \\r\\n173.8 ,93.4 ,159.9 ,172.3 ,9.7 ,1007.2 ,746.6 ,100 ,50.94 \\r\\n190.3 ,0.0 ,125.2 ,166.6 ,9.9 ,1079.0 ,798.9 ,100 ,33.56 \\r\\n250.0 ,0.0 ,95.7 ,191.8 ,5.3 ,948.9 ,857.2 ,100 ,41.16 \\r\\n213.5 ,0.0 ,174.2 ,159.2 ,11.7 ,1043.6 ,771.9 ,100 ,52.96 \\r\\n194.7 ,0.0 ,100.5 ,170.2 ,7.5 ,998.0 ,901.8 ,100 ,44.28 \\r\\n251.4 ,0.0 ,118.3 ,192.9 ,5.8 ,1043.6 ,754.3 ,100 ,40.15 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,28 ,57.03 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,28 ,44.42 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,28 ,51.02 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,10.3 ,967.0 ,712.0 ,28 ,53.39 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,3 ,35.36 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,3 ,25.02 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,3 ,23.35 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,7 ,52.01 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,7 ,38.02 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,7 ,39.30 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,56 ,61.07 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,56 ,56.14 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,11.6 ,967.0 ,712.0 ,56 ,55.25 \\r\\n446.0 ,24.0 ,79.0 ,162.0 ,10.3 ,967.0 ,712.0 ,56 ,54.77 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,14.3 ,938.0 ,845.0 ,28 ,50.24 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,13.9 ,938.0 ,845.0 ,28 ,46.68 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,11.6 ,938.0 ,845.0 ,28 ,46.68 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,14.3 ,938.0 ,845.0 ,3 ,22.75 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,13.9 ,938.0 ,845.0 ,3 ,25.51 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,11.6 ,938.0 ,845.0 ,3 ,34.77 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,14.3 ,938.0 ,845.0 ,7 ,36.84 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,13.9 ,938.0 ,845.0 ,7 ,45.90 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,11.6 ,938.0 ,845.0 ,7 ,41.67 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,14.3 ,938.0 ,845.0 ,56 ,56.34 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,13.9 ,938.0 ,845.0 ,56 ,47.97 \\r\\n387.0 ,20.0 ,94.0 ,157.0 ,11.6 ,938.0 ,845.0 ,56 ,61.46 \\r\\n355.0 ,19.0 ,97.0 ,145.0 ,13.1 ,967.0 ,871.0 ,28 ,44.03 \\r\\n355.0 ,19.0 ,97.0 ,145.0 ,12.3 ,967.0 ,871.0 ,28 ,55.45 \\r\\n491.0 ,26.0 ,123.0 ,210.0 ,3.9 ,882.0 ,699.0 ,28 ,55.55 \\r\\n491.0 ,26.0 ,123.0 ,201.0 ,3.9 ,822.0 ,699.0 ,28 ,57.92 \\r\\n491.0 ,26.0 ,123.0 ,210.0 ,3.9 ,882.0 ,699.0 ,3 ,25.61 \\r\\n491.0 ,26.0 ,123.0 ,210.0 ,3.9 ,882.0 ,699.0 ,7 ,33.49 \\r\\n491.0 ,26.0 ,123.0 ,210.0 ,3.9 ,882.0 ,699.0 ,56 ,59.59 \\r\\n491.0 ,26.0 ,123.0 ,201.0 ,3.9 ,822.0 ,699.0 ,3 ,29.55 \\r\\n491.0 ,26.0 ,123.0 ,201.0 ,3.9 ,822.0 ,699.0 ,7 ,37.92 \\r\\n491.0 ,26.0 ,123.0 ,201.0 ,3.9 ,822.0 ,699.0 ,56 ,61.86 \\r\\n424.0 ,22.0 ,132.0 ,178.0 ,8.5 ,822.0 ,750.0 ,28 ,62.05 \\r\\n424.0 ,22.0 ,132.0 ,178.0 ,8.5 ,882.0 ,750.0 ,3 ,32.01 \\r\\n424.0 ,22.0 ,132.0 ,168.0 ,8.9 ,822.0 ,750.0 ,28 ,72.10 \\r\\n424.0 ,22.0 ,132.0 ,178.0 ,8.5 ,822.0 ,750.0 ,7 ,39.00 \\r\\n424.0 ,22.0 ,132.0 ,178.0 ,8.5 ,822.0 ,750.0 ,56 ,65.70 \\r\\n424.0 ,22.0 ,132.0 ,168.0 ,8.9 ,822.0 ,750.0 ,3 ,32.11 \\r\\n424.0 ,22.0 ,132.0 ,168.0 ,8.9 ,822.0 ,750.0 ,7 ,40.29 \\r\\n424.0 ,22.0 ,132.0 ,168.0 ,8.9 ,822.0 ,750.0 ,56 ,74.36 \\r\\n202.0 ,11.0 ,141.0 ,206.0 ,1.7 ,942.0 ,801.0 ,28 ,21.97 \\r\\n202.0 ,11.0 ,141.0 ,206.0 ,1.7 ,942.0 ,801.0 ,3 ,9.85 \\r\\n202.0 ,11.0 ,141.0 ,206.0 ,1.7 ,942.0 ,801.0 ,7 ,15.07 \\r\\n202.0 ,11.0 ,141.0 ,206.0 ,1.7 ,942.0 ,801.0 ,56 ,23.25 \\r\\n284.0 ,15.0 ,141.0 ,179.0 ,5.5 ,842.0 ,801.0 ,28 ,43.73 \\r\\n284.0 ,15.0 ,141.0 ,179.0 ,5.5 ,842.0 ,801.0 ,3 ,13.40 \\r\\n284.0 ,15.0 ,141.0 ,179.0 ,5.5 ,842.0 ,801.0 ,7 ,24.13 \\r\\n284.0 ,15.0 ,141.0 ,179.0 ,5.5 ,842.0 ,801.0 ,56 ,44.52 \\r\\n359.0 ,19.0 ,141.0 ,154.0 ,10.9 ,942.0 ,801.0 ,28 ,62.94 \\r\\n359.0 ,19.0 ,141.0 ,154.0 ,10.9 ,942.0 ,801.0 ,28 ,59.49 \\r\\n359.0 ,19.0 ,141.0 ,154.0 ,10.9 ,942.0 ,801.0 ,3 ,25.12 \\r\\n359.0 ,19.0 ,141.0 ,154.0 ,10.9 ,942.0 ,801.0 ,3 ,23.64 \\r\\n359.0 ,19.0 ,141.0 ,154.0 ,10.9 ,942.0 ,801.0 ,7 ,35.75 \\r\\n359.0 ,19.0 ,141.0 ,154.0 ,10.9 ,942.0 ,801.0 ,7 ,38.61 \\r\\n359.0 ,19.0 ,141.0 ,154.0 ,10.9 ,942.0 ,801.0 ,56 ,68.75 \\r\\n359.0 ,19.0 ,141.0 ,154.0 ,10.9 ,942.0 ,801.0 ,56 ,66.78 \\r\\n436.0 ,0.0 ,0.0 ,218.0 ,0.0 ,838.4 ,719.7 ,28 ,23.85 \\r\\n289.0 ,0.0 ,0.0 ,192.0 ,0.0 ,913.2 ,895.3 ,90 ,32.07 \\r\\n289.0 ,0.0 ,0.0 ,192.0 ,0.0 ,913.2 ,895.3 ,3 ,11.65 \\r\\n393.0 ,0.0 ,0.0 ,192.0 ,0.0 ,940.6 ,785.6 ,3 ,19.20 \\r\\n393.0 ,0.0 ,0.0 ,192.0 ,0.0 ,940.6 ,785.6 ,90 ,48.85 \\r\\n393.0 ,0.0 ,0.0 ,192.0 ,0.0 ,940.6 ,785.6 ,28 ,39.60 \\r\\n480.0 ,0.0 ,0.0 ,192.0 ,0.0 ,936.2 ,712.2 ,28 ,43.94 \\r\\n480.0 ,0.0 ,0.0 ,192.0 ,0.0 ,936.2 ,712.2 ,7 ,34.57 \\r\\n480.0 ,0.0 ,0.0 ,192.0 ,0.0 ,936.2 ,712.2 ,90 ,54.32 \\r\\n480.0 ,0.0 ,0.0 ,192.0 ,0.0 ,936.2 ,712.2 ,3 ,24.40 \\r\\n333.0 ,0.0 ,0.0 ,192.0 ,0.0 ,931.2 ,842.6 ,3 ,15.62 \\r\\n255.0 ,0.0 ,0.0 ,192.0 ,0.0 ,889.8 ,945.0 ,90 ,21.86 \\r\\n255.0 ,0.0 ,0.0 ,192.0 ,0.0 ,889.8 ,945.0 ,7 ,10.22 \\r\\n289.0 ,0.0 ,0.0 ,192.0 ,0.0 ,913.2 ,895.3 ,7 ,14.60 \\r\\n255.0 ,0.0 ,0.0 ,192.0 ,0.0 ,889.8 ,945.0 ,28 ,18.75 \\r\\n333.0 ,0.0 ,0.0 ,192.0 ,0.0 ,931.2 ,842.6 ,28 ,31.97 \\r\\n333.0 ,0.0 ,0.0 ,192.0 ,0.0 ,931.2 ,842.6 ,7 ,23.40 \\r\\n289.0 ,0.0 ,0.0 ,192.0 ,0.0 ,913.2 ,895.3 ,28 ,25.57 \\r\\n333.0 ,0.0 ,0.0 ,192.0 ,0.0 ,931.2 ,842.6 ,90 ,41.68 \\r\\n393.0 ,0.0 ,0.0 ,192.0 ,0.0 ,940.6 ,785.6 ,7 ,27.74 \\r\\n255.0 ,0.0 ,0.0 ,192.0 ,0.0 ,889.8 ,945.0 ,3 ,8.20 \\r\\n158.8 ,238.2 ,0.0 ,185.7 ,0.0 ,1040.6 ,734.3 ,7 ,9.62 \\r\\n239.6 ,359.4 ,0.0 ,185.7 ,0.0 ,941.6 ,664.3 ,7 ,25.42 \\r\\n238.2 ,158.8 ,0.0 ,185.7 ,0.0 ,1040.6 ,734.3 ,7 ,15.69 \\r\\n181.9 ,272.8 ,0.0 ,185.7 ,0.0 ,1012.4 ,714.3 ,28 ,27.94 \\r\\n193.5 ,290.2 ,0.0 ,185.7 ,0.0 ,998.2 ,704.3 ,28 ,32.63 \\r\\n255.5 ,170.3 ,0.0 ,185.7 ,0.0 ,1026.6 ,724.3 ,7 ,17.24 \\r\\n272.8 ,181.9 ,0.0 ,185.7 ,0.0 ,1012.4 ,714.3 ,7 ,19.77 \\r\\n239.6 ,359.4 ,0.0 ,185.7 ,0.0 ,941.6 ,664.3 ,28 ,39.44 \\r\\n220.8 ,147.2 ,0.0 ,185.7 ,0.0 ,1055.0 ,744.3 ,28 ,25.75 \\r\\n397.0 ,0.0 ,0.0 ,185.7 ,0.0 ,1040.6 ,734.3 ,28 ,33.08 \\r\\n382.5 ,0.0 ,0.0 ,185.7 ,0.0 ,1047.8 ,739.3 ,7 ,24.07 \\r\\n210.7 ,316.1 ,0.0 ,185.7 ,0.0 ,977.0 ,689.3 ,7 ,21.82 \\r\\n158.8 ,238.2 ,0.0 ,185.7 ,0.0 ,1040.6 ,734.3 ,28 ,21.07 \\r\\n295.8 ,0.0 ,0.0 ,185.7 ,0.0 ,1091.4 ,769.3 ,7 ,14.84 \\r\\n255.5 ,170.3 ,0.0 ,185.7 ,0.0 ,1026.6 ,724.3 ,28 ,32.05 \\r\\n203.5 ,135.7 ,0.0 ,185.7 ,0.0 ,1076.2 ,759.3 ,7 ,11.96 \\r\\n397.0 ,0.0 ,0.0 ,185.7 ,0.0 ,1040.6 ,734.3 ,7 ,25.45 \\r\\n381.4 ,0.0 ,0.0 ,185.7 ,0.0 ,1104.6 ,784.3 ,28 ,22.49 \\r\\n295.8 ,0.0 ,0.0 ,185.7 ,0.0 ,1091.4 ,769.3 ,28 ,25.22 \\r\\n228.0 ,342.1 ,0.0 ,185.7 ,0.0 ,955.8 ,674.3 ,28 ,39.70 \\r\\n220.8 ,147.2 ,0.0 ,185.7 ,0.0 ,1055.0 ,744.3 ,7 ,13.09 \\r\\n316.1 ,210.7 ,0.0 ,185.7 ,0.0 ,977.0 ,689.3 ,28 ,38.70 \\r\\n135.7 ,203.5 ,0.0 ,185.7 ,0.0 ,1076.2 ,759.3 ,7 ,7.51 \\r\\n238.1 ,0.0 ,0.0 ,185.7 ,0.0 ,1118.8 ,789.3 ,28 ,17.58 \\r\\n339.2 ,0.0 ,0.0 ,185.7 ,0.0 ,1069.2 ,754.3 ,7 ,21.18 \\r\\n135.7 ,203.5 ,0.0 ,185.7 ,0.0 ,1076.2 ,759.3 ,28 ,18.20 \\r\\n193.5 ,290.2 ,0.0 ,185.7 ,0.0 ,998.2 ,704.3 ,7 ,17.20 \\r\\n203.5 ,135.7 ,0.0 ,185.7 ,0.0 ,1076.2 ,759.3 ,28 ,22.63 \\r\\n290.2 ,193.5 ,0.0 ,185.7 ,0.0 ,998.2 ,704.3 ,7 ,21.86 \\r\\n181.9 ,272.8 ,0.0 ,185.7 ,0.0 ,1012.4 ,714.3 ,7 ,12.37 \\r\\n170.3 ,155.5 ,0.0 ,185.7 ,0.0 ,1026.6 ,724.3 ,28 ,25.73 \\r\\n210.7 ,316.1 ,0.0 ,185.7 ,0.0 ,977.0 ,689.3 ,28 ,37.81 \\r\\n228.0 ,342.1 ,0.0 ,185.7 ,0.0 ,955.8 ,674.3 ,7 ,21.92 \\r\\n290.2 ,193.5 ,0.0 ,185.7 ,0.0 ,998.2 ,704.3 ,28 ,33.04 \\r\\n381.4 ,0.0 ,0.0 ,185.7 ,0.0 ,1104.6 ,784.3 ,7 ,14.54 \\r\\n238.2 ,158.8 ,0.0 ,185.7 ,0.0 ,1040.6 ,734.3 ,28 ,26.91 \\r\\n186.2 ,124.1 ,0.0 ,185.7 ,0.0 ,1083.4 ,764.3 ,7 ,8.00 \\r\\n339.2 ,0.0 ,0.0 ,185.7 ,0.0 ,1069.2 ,754.3 ,28 ,31.90 \\r\\n238.1 ,0.0 ,0.0 ,185.7 ,0.0 ,1118.8 ,789.3 ,7 ,10.34 \\r\\n252.5 ,0.0 ,0.0 ,185.7 ,0.0 ,1111.6 ,784.3 ,28 ,19.77 \\r\\n382.5 ,0.0 ,0.0 ,185.7 ,0.0 ,1047.8 ,739.3 ,28 ,37.44 \\r\\n252.5 ,0.0 ,0.0 ,185.7 ,0.0 ,1111.6 ,784.3 ,7 ,11.48 \\r\\n316.1 ,210.7 ,0.0 ,185.7 ,0.0 ,977.0 ,689.3 ,7 ,24.44 \\r\\n186.2 ,124.1 ,0.0 ,185.7 ,0.0 ,1083.4 ,764.3 ,28 ,17.60 \\r\\n170.3 ,155.5 ,0.0 ,185.7 ,0.0 ,1026.6 ,724.3 ,7 ,10.73 \\r\\n272.8 ,181.9 ,0.0 ,185.7 ,0.0 ,1012.4 ,714.3 ,28 ,31.38 \\r\\n339.0 ,0.0 ,0.0 ,197.0 ,0.0 ,968.0 ,781.0 ,3 ,13.22 \\r\\n339.0 ,0.0 ,0.0 ,197.0 ,0.0 ,968.0 ,781.0 ,7 ,20.97 \\r\\n339.0 ,0.0 ,0.0 ,197.0 ,0.0 ,968.0 ,781.0 ,14 ,27.04 \\r\\n339.0 ,0.0 ,0.0 ,197.0 ,0.0 ,968.0 ,781.0 ,28 ,32.04 \\r\\n339.0 ,0.0 ,0.0 ,197.0 ,0.0 ,968.0 ,781.0 ,90 ,35.17 \\r\\n339.0 ,0.0 ,0.0 ,197.0 ,0.0 ,968.0 ,781.0 ,180 ,36.45 \\r\\n339.0 ,0.0 ,0.0 ,197.0 ,0.0 ,968.0 ,781.0 ,365 ,38.89 \\r\\n236.0 ,0.0 ,0.0 ,194.0 ,0.0 ,968.0 ,885.0 ,3 ,6.47 \\r\\n236.0 ,0.0 ,0.0 ,194.0 ,0.0 ,968.0 ,885.0 ,14 ,12.84 \\r\\n236.0 ,0.0 ,0.0 ,194.0 ,0.0 ,968.0 ,885.0 ,28 ,18.42 \\r\\n236.0 ,0.0 ,0.0 ,194.0 ,0.0 ,968.0 ,885.0 ,90 ,21.95 \\r\\n236.0 ,0.0 ,0.0 ,193.0 ,0.0 ,968.0 ,885.0 ,180 ,24.10 \\r\\n236.0 ,0.0 ,0.0 ,193.0 ,0.0 ,968.0 ,885.0 ,365 ,25.08 \\r\\n277.0 ,0.0 ,0.0 ,191.0 ,0.0 ,968.0 ,856.0 ,14 ,21.26 \\r\\n277.0 ,0.0 ,0.0 ,191.0 ,0.0 ,968.0 ,856.0 ,28 ,25.97 \\r\\n277.0 ,0.0 ,0.0 ,191.0 ,0.0 ,968.0 ,856.0 ,3 ,11.36 \\r\\n277.0 ,0.0 ,0.0 ,191.0 ,0.0 ,968.0 ,856.0 ,90 ,31.25 \\r\\n277.0 ,0.0 ,0.0 ,191.0 ,0.0 ,968.0 ,856.0 ,180 ,32.33 \\r\\n277.0 ,0.0 ,0.0 ,191.0 ,0.0 ,968.0 ,856.0 ,360 ,33.70 \\r\\n254.0 ,0.0 ,0.0 ,198.0 ,0.0 ,968.0 ,863.0 ,3 ,9.31 \\r\\n254.0 ,0.0 ,0.0 ,198.0 ,0.0 ,968.0 ,863.0 ,90 ,26.94 \\r\\n254.0 ,0.0 ,0.0 ,198.0 ,0.0 ,968.0 ,863.0 ,180 ,27.63 \\r\\n254.0 ,0.0 ,0.0 ,198.0 ,0.0 ,968.0 ,863.0 ,365 ,29.79 \\r\\n307.0 ,0.0 ,0.0 ,193.0 ,0.0 ,968.0 ,812.0 ,180 ,34.49 \\r\\n307.0 ,0.0 ,0.0 ,193.0 ,0.0 ,968.0 ,812.0 ,365 ,36.15 \\r\\n307.0 ,0.0 ,0.0 ,193.0 ,0.0 ,968.0 ,812.0 ,3 ,12.54 \\r\\n307.0 ,0.0 ,0.0 ,193.0 ,0.0 ,968.0 ,812.0 ,28 ,27.53 \\r\\n307.0 ,0.0 ,0.0 ,193.0 ,0.0 ,968.0 ,812.0 ,90 ,32.92 \\r\\n236.0 ,0.0 ,0.0 ,193.0 ,0.0 ,968.0 ,885.0 ,7 ,9.99 \\r\\n200.0 ,0.0 ,0.0 ,180.0 ,0.0 ,1125.0 ,845.0 ,7 ,7.84 \\r\\n200.0 ,0.0 ,0.0 ,180.0 ,0.0 ,1125.0 ,845.0 ,28 ,12.25 \\r\\n225.0 ,0.0 ,0.0 ,181.0 ,0.0 ,1113.0 ,833.0 ,7 ,11.17 \\r\\n225.0 ,0.0 ,0.0 ,181.0 ,0.0 ,1113.0 ,833.0 ,28 ,17.34 \\r\\n325.0 ,0.0 ,0.0 ,184.0 ,0.0 ,1063.0 ,783.0 ,7 ,17.54 \\r\\n325.0 ,0.0 ,0.0 ,184.0 ,0.0 ,1063.0 ,783.0 ,28 ,30.57 \\r\\n275.0 ,0.0 ,0.0 ,183.0 ,0.0 ,1088.0 ,808.0 ,7 ,14.20 \\r\\n275.0 ,0.0 ,0.0 ,183.0 ,0.0 ,1088.0 ,808.0 ,28 ,24.50 \\r\\n300.0 ,0.0 ,0.0 ,184.0 ,0.0 ,1075.0 ,795.0 ,7 ,15.58 \\r\\n300.0 ,0.0 ,0.0 ,184.0 ,0.0 ,1075.0 ,795.0 ,28 ,26.85 \\r\\n375.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1038.0 ,758.0 ,7 ,26.06 \\r\\n375.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1038.0 ,758.0 ,28 ,38.21 \\r\\n400.0 ,0.0 ,0.0 ,187.0 ,0.0 ,1025.0 ,745.0 ,28 ,43.70 \\r\\n400.0 ,0.0 ,0.0 ,187.0 ,0.0 ,1025.0 ,745.0 ,7 ,30.14 \\r\\n250.0 ,0.0 ,0.0 ,182.0 ,0.0 ,1100.0 ,820.0 ,7 ,12.73 \\r\\n250.0 ,0.0 ,0.0 ,182.0 ,0.0 ,1100.0 ,820.0 ,28 ,20.87 \\r\\n350.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1050.0 ,770.0 ,7 ,20.28 \\r\\n350.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1050.0 ,770.0 ,28 ,34.29 \\r\\n203.5 ,305.3 ,0.0 ,203.5 ,0.0 ,963.4 ,630.0 ,7 ,19.54 \\r\\n250.2 ,166.8 ,0.0 ,203.5 ,0.0 ,977.6 ,694.1 ,90 ,47.71 \\r\\n157.0 ,236.0 ,0.0 ,192.0 ,0.0 ,935.4 ,781.2 ,90 ,43.38 \\r\\n141.3 ,212.0 ,0.0 ,203.5 ,0.0 ,971.8 ,748.5 ,28 ,29.89 \\r\\n166.8 ,250.2 ,0.0 ,203.5 ,0.0 ,975.6 ,692.6 ,3 ,6.90 \\r\\n122.6 ,183.9 ,0.0 ,203.5 ,0.0 ,958.2 ,800.1 ,90 ,33.19 \\r\\n183.9 ,122.6 ,0.0 ,203.5 ,0.0 ,959.2 ,800.0 ,3 ,4.90 \\r\\n102.0 ,153.0 ,0.0 ,192.0 ,0.0 ,887.0 ,942.0 ,3 ,4.57 \\r\\n102.0 ,153.0 ,0.0 ,192.0 ,0.0 ,887.0 ,942.0 ,90 ,25.46 \\r\\n122.6 ,183.9 ,0.0 ,203.5 ,0.0 ,958.2 ,800.1 ,28 ,24.29 \\r\\n166.8 ,250.2 ,0.0 ,203.5 ,0.0 ,975.6 ,692.6 ,28 ,33.95 \\r\\n200.0 ,133.0 ,0.0 ,192.0 ,0.0 ,965.4 ,806.2 ,3 ,11.41 \\r\\n108.3 ,162.4 ,0.0 ,203.5 ,0.0 ,938.2 ,849.0 ,28 ,20.59 \\r\\n305.3 ,203.5 ,0.0 ,203.5 ,0.0 ,965.4 ,631.0 ,7 ,25.89 \\r\\n108.3 ,162.4 ,0.0 ,203.5 ,0.0 ,938.2 ,849.0 ,90 ,29.23 \\r\\n116.0 ,173.0 ,0.0 ,192.0 ,0.0 ,909.8 ,891.9 ,90 ,31.02 \\r\\n141.3 ,212.0 ,0.0 ,203.5 ,0.0 ,971.8 ,748.5 ,7 ,10.39 \\r\\n157.0 ,236.0 ,0.0 ,192.0 ,0.0 ,935.4 ,781.2 ,28 ,33.66 \\r\\n133.0 ,200.0 ,0.0 ,192.0 ,0.0 ,927.4 ,839.2 ,28 ,27.87 \\r\\n250.2 ,166.8 ,0.0 ,203.5 ,0.0 ,977.6 ,694.1 ,7 ,19.35 \\r\\n173.0 ,116.0 ,0.0 ,192.0 ,0.0 ,946.8 ,856.8 ,7 ,11.39 \\r\\n192.0 ,288.0 ,0.0 ,192.0 ,0.0 ,929.8 ,716.1 ,3 ,12.79 \\r\\n192.0 ,288.0 ,0.0 ,192.0 ,0.0 ,929.8 ,716.1 ,28 ,39.32 \\r\\n153.0 ,102.0 ,0.0 ,192.0 ,0.0 ,888.0 ,943.1 ,3 ,4.78 \\r\\n288.0 ,192.0 ,0.0 ,192.0 ,0.0 ,932.0 ,717.8 ,3 ,16.11 \\r\\n305.3 ,203.5 ,0.0 ,203.5 ,0.0 ,965.4 ,631.0 ,28 ,43.38 \\r\\n236.0 ,157.0 ,0.0 ,192.0 ,0.0 ,972.6 ,749.1 ,7 ,20.42 \\r\\n173.0 ,116.0 ,0.0 ,192.0 ,0.0 ,946.8 ,856.8 ,3 ,6.94 \\r\\n212.0 ,141.3 ,0.0 ,203.5 ,0.0 ,973.4 ,750.0 ,7 ,15.03 \\r\\n236.0 ,157.0 ,0.0 ,192.0 ,0.0 ,972.6 ,749.1 ,3 ,13.57 \\r\\n183.9 ,122.6 ,0.0 ,203.5 ,0.0 ,959.2 ,800.0 ,90 ,32.53 \\r\\n166.8 ,250.2 ,0.0 ,203.5 ,0.0 ,975.6 ,692.6 ,7 ,15.75 \\r\\n102.0 ,153.0 ,0.0 ,192.0 ,0.0 ,887.0 ,942.0 ,7 ,7.68 \\r\\n288.0 ,192.0 ,0.0 ,192.0 ,0.0 ,932.0 ,717.8 ,28 ,38.80 \\r\\n212.0 ,141.3 ,0.0 ,203.5 ,0.0 ,973.4 ,750.0 ,28 ,33.00 \\r\\n102.0 ,153.0 ,0.0 ,192.0 ,0.0 ,887.0 ,942.0 ,28 ,17.28 \\r\\n173.0 ,116.0 ,0.0 ,192.0 ,0.0 ,946.8 ,856.8 ,28 ,24.28 \\r\\n183.9 ,122.6 ,0.0 ,203.5 ,0.0 ,959.2 ,800.0 ,28 ,24.05 \\r\\n133.0 ,200.0 ,0.0 ,192.0 ,0.0 ,927.4 ,839.2 ,90 ,36.59 \\r\\n192.0 ,288.0 ,0.0 ,192.0 ,0.0 ,929.8 ,716.1 ,90 ,50.73 \\r\\n133.0 ,200.0 ,0.0 ,192.0 ,0.0 ,927.4 ,839.2 ,7 ,13.66 \\r\\n305.3 ,203.5 ,0.0 ,203.5 ,0.0 ,965.4 ,631.0 ,3 ,14.14 \\r\\n236.0 ,157.0 ,0.0 ,192.0 ,0.0 ,972.6 ,749.1 ,90 ,47.78 \\r\\n108.3 ,162.4 ,0.0 ,203.5 ,0.0 ,938.2 ,849.0 ,3 ,2.33 \\r\\n157.0 ,236.0 ,0.0 ,192.0 ,0.0 ,935.4 ,781.2 ,7 ,16.89 \\r\\n288.0 ,192.0 ,0.0 ,192.0 ,0.0 ,932.0 ,717.8 ,7 ,23.52 \\r\\n212.0 ,141.3 ,0.0 ,203.5 ,0.0 ,973.4 ,750.0 ,3 ,6.81 \\r\\n212.0 ,141.3 ,0.0 ,203.5 ,0.0 ,973.4 ,750.0 ,90 ,39.70 \\r\\n153.0 ,102.0 ,0.0 ,192.0 ,0.0 ,888.0 ,943.1 ,28 ,17.96 \\r\\n236.0 ,157.0 ,0.0 ,192.0 ,0.0 ,972.6 ,749.1 ,28 ,32.88 \\r\\n116.0 ,173.0 ,0.0 ,192.0 ,0.0 ,909.8 ,891.9 ,28 ,22.35 \\r\\n183.9 ,122.6 ,0.0 ,203.5 ,0.0 ,959.2 ,800.0 ,7 ,10.79 \\r\\n108.3 ,162.4 ,0.0 ,203.5 ,0.0 ,938.2 ,849.0 ,7 ,7.72 \\r\\n203.5 ,305.3 ,0.0 ,203.5 ,0.0 ,963.4 ,630.0 ,28 ,41.68 \\r\\n203.5 ,305.3 ,0.0 ,203.5 ,0.0 ,963.4 ,630.0 ,3 ,9.56 \\r\\n133.0 ,200.0 ,0.0 ,192.0 ,0.0 ,927.4 ,839.2 ,3 ,6.88 \\r\\n288.0 ,192.0 ,0.0 ,192.0 ,0.0 ,932.0 ,717.8 ,90 ,50.53 \\r\\n200.0 ,133.0 ,0.0 ,192.0 ,0.0 ,965.4 ,806.2 ,7 ,17.17 \\r\\n200.0 ,133.0 ,0.0 ,192.0 ,0.0 ,965.4 ,806.2 ,28 ,30.44 \\r\\n250.2 ,166.8 ,0.0 ,203.5 ,0.0 ,977.6 ,694.1 ,3 ,9.73 \\r\\n122.6 ,183.9 ,0.0 ,203.5 ,0.0 ,958.2 ,800.1 ,3 ,3.32 \\r\\n153.0 ,102.0 ,0.0 ,192.0 ,0.0 ,888.0 ,943.1 ,90 ,26.32 \\r\\n200.0 ,133.0 ,0.0 ,192.0 ,0.0 ,965.4 ,806.2 ,90 ,43.25 \\r\\n116.0 ,173.0 ,0.0 ,192.0 ,0.0 ,909.8 ,891.9 ,3 ,6.28 \\r\\n173.0 ,116.0 ,0.0 ,192.0 ,0.0 ,946.8 ,856.8 ,90 ,32.10 \\r\\n250.2 ,166.8 ,0.0 ,203.5 ,0.0 ,977.6 ,694.1 ,28 ,36.96 \\r\\n305.3 ,203.5 ,0.0 ,203.5 ,0.0 ,965.4 ,631.0 ,90 ,54.60 \\r\\n192.0 ,288.0 ,0.0 ,192.0 ,0.0 ,929.8 ,716.1 ,7 ,21.48 \\r\\n157.0 ,236.0 ,0.0 ,192.0 ,0.0 ,935.4 ,781.2 ,3 ,9.69 \\r\\n153.0 ,102.0 ,0.0 ,192.0 ,0.0 ,888.0 ,943.1 ,7 ,8.37 \\r\\n141.3 ,212.0 ,0.0 ,203.5 ,0.0 ,971.8 ,748.5 ,90 ,39.66 \\r\\n116.0 ,173.0 ,0.0 ,192.0 ,0.0 ,909.8 ,891.9 ,7 ,10.09 \\r\\n141.3 ,212.0 ,0.0 ,203.5 ,0.0 ,971.8 ,748.5 ,3 ,4.83 \\r\\n122.6 ,183.9 ,0.0 ,203.5 ,0.0 ,958.2 ,800.1 ,7 ,10.35 \\r\\n166.8 ,250.2 ,0.0 ,203.5 ,0.0 ,975.6 ,692.6 ,90 ,43.57 \\r\\n203.5 ,305.3 ,0.0 ,203.5 ,0.0 ,963.4 ,630.0 ,90 ,51.86 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1012.0 ,830.0 ,3 ,11.85 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1012.0 ,830.0 ,7 ,17.24 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1012.0 ,830.0 ,28 ,27.83 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1012.0 ,830.0 ,90 ,35.76 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1012.0 ,830.0 ,120 ,38.70 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1025.0 ,821.0 ,3 ,14.31 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1025.0 ,821.0 ,7 ,17.44 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1025.0 ,821.0 ,28 ,31.74 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1025.0 ,821.0 ,90 ,37.91 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1025.0 ,821.0 ,120 ,39.38 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1056.0 ,809.0 ,3 ,15.87 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1056.0 ,809.0 ,7 ,9.01 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1056.0 ,809.0 ,28 ,33.61 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1056.0 ,809.0 ,90 ,40.66 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1056.0 ,809.0 ,120 ,40.86 \\r\\n238.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1119.0 ,789.0 ,7 ,12.05 \\r\\n238.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1119.0 ,789.0 ,28 ,17.54 \\r\\n296.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1090.0 ,769.0 ,7 ,18.91 \\r\\n296.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1090.0 ,769.0 ,28 ,25.18 \\r\\n297.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1040.0 ,734.0 ,7 ,30.96 \\r\\n480.0 ,0.0 ,0.0 ,192.0 ,0.0 ,936.0 ,721.0 ,28 ,43.89 \\r\\n480.0 ,0.0 ,0.0 ,192.0 ,0.0 ,936.0 ,721.0 ,90 ,54.28 \\r\\n397.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1040.0 ,734.0 ,28 ,36.94 \\r\\n281.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1104.0 ,774.0 ,7 ,14.50 \\r\\n281.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1104.0 ,774.0 ,28 ,22.44 \\r\\n500.0 ,0.0 ,0.0 ,200.0 ,0.0 ,1125.0 ,613.0 ,1 ,12.64 \\r\\n500.0 ,0.0 ,0.0 ,200.0 ,0.0 ,1125.0 ,613.0 ,3 ,26.06 \\r\\n500.0 ,0.0 ,0.0 ,200.0 ,0.0 ,1125.0 ,613.0 ,7 ,33.21 \\r\\n500.0 ,0.0 ,0.0 ,200.0 ,0.0 ,1125.0 ,613.0 ,14 ,36.94 \\r\\n500.0 ,0.0 ,0.0 ,200.0 ,0.0 ,1125.0 ,613.0 ,28 ,44.09 \\r\\n540.0 ,0.0 ,0.0 ,173.0 ,0.0 ,1125.0 ,613.0 ,7 ,52.61 \\r\\n540.0 ,0.0 ,0.0 ,173.0 ,0.0 ,1125.0 ,613.0 ,14 ,59.76 \\r\\n540.0 ,0.0 ,0.0 ,173.0 ,0.0 ,1125.0 ,613.0 ,28 ,67.31 \\r\\n540.0 ,0.0 ,0.0 ,173.0 ,0.0 ,1125.0 ,613.0 ,90 ,69.66 \\r\\n540.0 ,0.0 ,0.0 ,173.0 ,0.0 ,1125.0 ,613.0 ,180 ,71.62 \\r\\n540.0 ,0.0 ,0.0 ,173.0 ,0.0 ,1125.0 ,613.0 ,270 ,74.17 \\r\\n350.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,775.0 ,7 ,18.13 \\r\\n350.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,775.0 ,14 ,22.53 \\r\\n350.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,775.0 ,28 ,27.34 \\r\\n350.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,775.0 ,56 ,29.98 \\r\\n350.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,775.0 ,90 ,31.35 \\r\\n350.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,775.0 ,180 ,32.72 \\r\\n385.0 ,0.0 ,0.0 ,186.0 ,0.0 ,966.0 ,763.0 ,1 ,6.27 \\r\\n385.0 ,0.0 ,0.0 ,186.0 ,0.0 ,966.0 ,763.0 ,3 ,14.70 \\r\\n385.0 ,0.0 ,0.0 ,186.0 ,0.0 ,966.0 ,763.0 ,7 ,23.22 \\r\\n385.0 ,0.0 ,0.0 ,186.0 ,0.0 ,966.0 ,763.0 ,14 ,27.92 \\r\\n385.0 ,0.0 ,0.0 ,186.0 ,0.0 ,966.0 ,763.0 ,28 ,31.35 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,978.0 ,825.0 ,180 ,39.00 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,978.0 ,825.0 ,360 ,41.24 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.0 ,3 ,14.99 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,978.0 ,825.0 ,3 ,13.52 \\r\\n382.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1047.0 ,739.0 ,7 ,24.00 \\r\\n382.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1047.0 ,739.0 ,28 ,37.42 \\r\\n382.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1111.0 ,784.0 ,7 ,11.47 \\r\\n281.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1104.0 ,774.0 ,28 ,22.44 \\r\\n339.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1069.0 ,754.0 ,7 ,21.16 \\r\\n339.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1069.0 ,754.0 ,28 ,31.84 \\r\\n295.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1069.0 ,769.0 ,7 ,14.80 \\r\\n295.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1069.0 ,769.0 ,28 ,25.18 \\r\\n238.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1118.0 ,789.0 ,28 ,17.54 \\r\\n296.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1085.0 ,765.0 ,7 ,14.20 \\r\\n296.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1085.0 ,765.0 ,28 ,21.65 \\r\\n296.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1085.0 ,765.0 ,90 ,29.39 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,879.0 ,825.0 ,3 ,13.52 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,978.0 ,825.0 ,7 ,16.26 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,978.0 ,825.0 ,28 ,31.45 \\r\\n331.0 ,0.0 ,0.0 ,192.0 ,0.0 ,978.0 ,825.0 ,90 ,37.23 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.0 ,7 ,18.13 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.0 ,28 ,32.72 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.0 ,90 ,39.49 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.0 ,180 ,41.05 \\r\\n349.0 ,0.0 ,0.0 ,192.0 ,0.0 ,1047.0 ,806.0 ,360 ,42.13 \\r\\n302.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,817.0 ,14 ,18.13 \\r\\n302.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,817.0 ,180 ,26.74 \\r\\n525.0 ,0.0 ,0.0 ,189.0 ,0.0 ,1125.0 ,613.0 ,180 ,61.92 \\r\\n500.0 ,0.0 ,0.0 ,200.0 ,0.0 ,1125.0 ,613.0 ,90 ,47.22 \\r\\n500.0 ,0.0 ,0.0 ,200.0 ,0.0 ,1125.0 ,613.0 ,180 ,51.04 \\r\\n500.0 ,0.0 ,0.0 ,200.0 ,0.0 ,1125.0 ,613.0 ,270 ,55.16 \\r\\n540.0 ,0.0 ,0.0 ,173.0 ,0.0 ,1125.0 ,613.0 ,3 ,41.64 \\r\\n252.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1111.0 ,784.0 ,7 ,13.71 \\r\\n252.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1111.0 ,784.0 ,28 ,19.69 \\r\\n339.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1060.0 ,754.0 ,28 ,31.65 \\r\\n393.0 ,0.0 ,0.0 ,192.0 ,0.0 ,940.0 ,758.0 ,3 ,19.11 \\r\\n393.0 ,0.0 ,0.0 ,192.0 ,0.0 ,940.0 ,758.0 ,28 ,39.58 \\r\\n393.0 ,0.0 ,0.0 ,192.0 ,0.0 ,940.0 ,758.0 ,90 ,48.79 \\r\\n382.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1047.0 ,739.0 ,7 ,24.00 \\r\\n382.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1047.0 ,739.0 ,28 ,37.42 \\r\\n252.0 ,0.0 ,0.0 ,186.0 ,0.0 ,1111.0 ,784.0 ,7 ,11.47 \\r\\n252.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1111.0 ,784.0 ,28 ,19.69 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,970.0 ,850.0 ,7 ,14.99 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,970.0 ,850.0 ,28 ,27.92 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,970.0 ,850.0 ,90 ,34.68 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,970.0 ,850.0 ,180 ,37.33 \\r\\n310.0 ,0.0 ,0.0 ,192.0 ,0.0 ,970.0 ,850.0 ,360 ,38.11 \\r\\n525.0 ,0.0 ,0.0 ,189.0 ,0.0 ,1125.0 ,613.0 ,3 ,33.80 \\r\\n525.0 ,0.0 ,0.0 ,189.0 ,0.0 ,1125.0 ,613.0 ,7 ,42.42 \\r\\n525.0 ,0.0 ,0.0 ,189.0 ,0.0 ,1125.0 ,613.0 ,14 ,48.40 \\r\\n525.0 ,0.0 ,0.0 ,189.0 ,0.0 ,1125.0 ,613.0 ,28 ,55.94 \\r\\n525.0 ,0.0 ,0.0 ,189.0 ,0.0 ,1125.0 ,613.0 ,90 ,58.78 \\r\\n525.0 ,0.0 ,0.0 ,189.0 ,0.0 ,1125.0 ,613.0 ,270 ,67.11 \\r\\n322.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,800.0 ,14 ,20.77 \\r\\n322.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,800.0 ,28 ,25.18 \\r\\n322.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,800.0 ,180 ,29.59 \\r\\n302.0 ,0.0 ,0.0 ,203.0 ,0.0 ,974.0 ,817.0 ,28 ,21.75 \\r\\n397.0 ,0.0 ,0.0 ,185.0 ,0.0 ,1040.0 ,734.0 ,28 ,39.09 \\r\\n480.0 ,0.0 ,0.0 ,192.0 ,0.0 ,936.0 ,721.0 ,3 ,24.39 \\r\\n522.0 ,0.0 ,0.0 ,146.0 ,0.0 ,896.0 ,896.0 ,7 ,50.51 \\r\\n522.0 ,0.0 ,0.0 ,146.0 ,0.0 ,896.0 ,896.0 ,28 ,74.99 \\r\\n273.0 ,105.0 ,82.0 ,210.0 ,9.0 ,904.0 ,680.0 ,28 ,37.17 \\r\\n162.0 ,190.0 ,148.0 ,179.0 ,19.0 ,838.0 ,741.0 ,28 ,33.76 \\r\\n154.0 ,144.0 ,112.0 ,220.0 ,10.0 ,923.0 ,658.0 ,28 ,16.50 \\r\\n147.0 ,115.0 ,89.0 ,202.0 ,9.0 ,860.0 ,829.0 ,28 ,19.99 \\r\\n152.0 ,178.0 ,139.0 ,168.0 ,18.0 ,944.0 ,695.0 ,28 ,36.35 \\r\\n310.0 ,143.0 ,111.0 ,168.0 ,22.0 ,914.0 ,651.0 ,28 ,33.69 \\r\\n144.0 ,0.0 ,175.0 ,158.0 ,18.0 ,943.0 ,844.0 ,28 ,15.42 \\r\\n304.0 ,140.0 ,0.0 ,214.0 ,6.0 ,895.0 ,722.0 ,28 ,33.42 \\r\\n374.0 ,0.0 ,0.0 ,190.0 ,7.0 ,1013.0 ,730.0 ,28 ,39.05 \\r\\n159.0 ,149.0 ,116.0 ,175.0 ,15.0 ,953.0 ,720.0 ,28 ,27.68 \\r\\n153.0 ,239.0 ,0.0 ,200.0 ,6.0 ,1002.0 ,684.0 ,28 ,26.86 \\r\\n310.0 ,143.0 ,0.0 ,168.0 ,10.0 ,914.0 ,804.0 ,28 ,45.30 \\r\\n305.0 ,0.0 ,100.0 ,196.0 ,10.0 ,959.0 ,705.0 ,28 ,30.12 \\r\\n151.0 ,0.0 ,184.0 ,167.0 ,12.0 ,991.0 ,772.0 ,28 ,15.57 \\r\\n142.0 ,167.0 ,130.0 ,174.0 ,11.0 ,883.0 ,785.0 ,28 ,44.61 \\r\\n298.0 ,137.0 ,107.0 ,201.0 ,6.0 ,878.0 ,655.0 ,28 ,53.52 \\r\\n321.0 ,164.0 ,0.0 ,190.0 ,5.0 ,870.0 ,774.0 ,28 ,57.21 \\r\\n366.0 ,187.0 ,0.0 ,191.0 ,7.0 ,824.0 ,757.0 ,28 ,65.91 \\r\\n280.0 ,129.0 ,100.0 ,172.0 ,9.0 ,825.0 ,805.0 ,28 ,52.82 \\r\\n252.0 ,97.0 ,76.0 ,194.0 ,8.0 ,835.0 ,821.0 ,28 ,33.40 \\r\\n165.0 ,0.0 ,150.0 ,182.0 ,12.0 ,1023.0 ,729.0 ,28 ,18.03 \\r\\n156.0 ,243.0 ,0.0 ,180.0 ,11.0 ,1022.0 ,698.0 ,28 ,37.36 \\r\\n160.0 ,188.0 ,146.0 ,203.0 ,11.0 ,829.0 ,710.0 ,28 ,32.84 \\r\\n298.0 ,0.0 ,107.0 ,186.0 ,6.0 ,879.0 ,815.0 ,28 ,42.64 \\r\\n318.0 ,0.0 ,126.0 ,210.0 ,6.0 ,861.0 ,737.0 ,28 ,40.06 \\r\\n287.0 ,121.0 ,94.0 ,188.0 ,9.0 ,904.0 ,696.0 ,28 ,41.94 \\r\\n326.0 ,166.0 ,0.0 ,174.0 ,9.0 ,882.0 ,790.0 ,28 ,61.23 \\r\\n356.0 ,0.0 ,142.0 ,193.0 ,11.0 ,801.0 ,778.0 ,28 ,40.87 \\r\\n132.0 ,207.0 ,161.0 ,179.0 ,5.0 ,867.0 ,736.0 ,28 ,33.30 \\r\\n322.0 ,149.0 ,0.0 ,186.0 ,8.0 ,951.0 ,709.0 ,28 ,52.42 \\r\\n164.0 ,0.0 ,200.0 ,181.0 ,13.0 ,849.0 ,846.0 ,28 ,15.09 \\r\\n314.0 ,0.0 ,113.0 ,170.0 ,10.0 ,925.0 ,783.0 ,28 ,38.46 \\r\\n321.0 ,0.0 ,128.0 ,182.0 ,11.0 ,870.0 ,780.0 ,28 ,37.26 \\r\\n140.0 ,164.0 ,128.0 ,237.0 ,6.0 ,869.0 ,656.0 ,28 ,35.23 \\r\\n288.0 ,121.0 ,0.0 ,177.0 ,7.0 ,908.0 ,829.0 ,28 ,42.13 \\r\\n298.0 ,0.0 ,107.0 ,210.0 ,11.0 ,880.0 ,744.0 ,28 ,31.87 \\r\\n265.0 ,111.0 ,86.0 ,195.0 ,6.0 ,833.0 ,790.0 ,28 ,41.54 \\r\\n160.0 ,250.0 ,0.0 ,168.0 ,12.0 ,1049.0 ,688.0 ,28 ,39.45 \\r\\n166.0 ,260.0 ,0.0 ,183.0 ,13.0 ,859.0 ,827.0 ,28 ,37.91 \\r\\n276.0 ,116.0 ,90.0 ,180.0 ,9.0 ,870.0 ,768.0 ,28 ,44.28 \\r\\n322.0 ,0.0 ,116.0 ,196.0 ,10.0 ,818.0 ,813.0 ,28 ,31.18 \\r\\n149.0 ,139.0 ,109.0 ,193.0 ,6.0 ,892.0 ,780.0 ,28 ,23.69 \\r\\n159.0 ,187.0 ,0.0 ,176.0 ,11.0 ,990.0 ,789.0 ,28 ,32.76 \\r\\n261.0 ,100.0 ,78.0 ,201.0 ,9.0 ,864.0 ,761.0 ,28 ,32.40 \\r\\n237.0 ,92.0 ,71.0 ,247.0 ,6.0 ,853.0 ,695.0 ,28 ,28.63 \\r\\n313.0 ,0.0 ,113.0 ,178.0 ,8.0 ,1002.0 ,689.0 ,28 ,36.80 \\r\\n155.0 ,183.0 ,0.0 ,193.0 ,9.0 ,1047.0 ,697.0 ,28 ,18.28 \\r\\n146.0 ,230.0 ,0.0 ,202.0 ,3.0 ,827.0 ,872.0 ,28 ,33.06 \\r\\n296.0 ,0.0 ,107.0 ,221.0 ,11.0 ,819.0 ,778.0 ,28 ,31.42 \\r\\n133.0 ,210.0 ,0.0 ,196.0 ,3.0 ,949.0 ,795.0 ,28 ,31.03 \\r\\n313.0 ,145.0 ,0.0 ,178.0 ,8.0 ,867.0 ,824.0 ,28 ,44.39 \\r\\n152.0 ,0.0 ,112.0 ,184.0 ,8.0 ,992.0 ,816.0 ,28 ,12.18 \\r\\n153.0 ,145.0 ,113.0 ,178.0 ,8.0 ,1002.0 ,689.0 ,28 ,25.56 \\r\\n140.0 ,133.0 ,103.0 ,200.0 ,7.0 ,916.0 ,753.0 ,28 ,36.44 \\r\\n149.0 ,236.0 ,0.0 ,176.0 ,13.0 ,847.0 ,893.0 ,28 ,32.96 \\r\\n300.0 ,0.0 ,120.0 ,212.0 ,10.0 ,878.0 ,728.0 ,28 ,23.84 \\r\\n153.0 ,145.0 ,113.0 ,178.0 ,8.0 ,867.0 ,824.0 ,28 ,26.23 \\r\\n148.0 ,0.0 ,137.0 ,158.0 ,16.0 ,1002.0 ,830.0 ,28 ,17.95 \\r\\n326.0 ,0.0 ,138.0 ,199.0 ,11.0 ,801.0 ,792.0 ,28 ,40.68 \\r\\n153.0 ,145.0 ,0.0 ,178.0 ,8.0 ,1000.0 ,822.0 ,28 ,19.01 \\r\\n262.0 ,111.0 ,86.0 ,195.0 ,5.0 ,895.0 ,733.0 ,28 ,33.72 \\r\\n158.0 ,0.0 ,195.0 ,220.0 ,11.0 ,898.0 ,713.0 ,28 ,8.54 \\r\\n151.0 ,0.0 ,185.0 ,167.0 ,16.0 ,1074.0 ,678.0 ,28 ,13.46 \\r\\n273.0 ,0.0 ,90.0 ,199.0 ,11.0 ,931.0 ,762.0 ,28 ,32.24 \\r\\n149.0 ,118.0 ,92.0 ,183.0 ,7.0 ,953.0 ,780.0 ,28 ,23.52 \\r\\n143.0 ,169.0 ,143.0 ,191.0 ,8.0 ,967.0 ,643.0 ,28 ,29.72 \\r\\n260.0 ,101.0 ,78.0 ,171.0 ,10.0 ,936.0 ,763.0 ,28 ,49.77 \\r\\n313.0 ,161.0 ,0.0 ,178.0 ,10.0 ,917.0 ,759.0 ,28 ,52.44 \\r\\n284.0 ,120.0 ,0.0 ,168.0 ,7.0 ,970.0 ,794.0 ,28 ,40.93 \\r\\n336.0 ,0.0 ,0.0 ,182.0 ,3.0 ,986.0 ,817.0 ,28 ,44.86 \\r\\n145.0 ,0.0 ,134.0 ,181.0 ,11.0 ,979.0 ,812.0 ,28 ,13.20 \\r\\n150.0 ,237.0 ,0.0 ,174.0 ,12.0 ,1069.0 ,675.0 ,28 ,37.43 \\r\\n144.0 ,170.0 ,133.0 ,192.0 ,8.0 ,814.0 ,805.0 ,28 ,29.87 \\r\\n331.0 ,170.0 ,0.0 ,195.0 ,8.0 ,811.0 ,802.0 ,28 ,56.61 \\r\\n155.0 ,0.0 ,143.0 ,193.0 ,9.0 ,1047.0 ,697.0 ,28 ,12.46 \\r\\n155.0 ,183.0 ,0.0 ,193.0 ,9.0 ,877.0 ,868.0 ,28 ,23.79 \\r\\n135.0 ,0.0 ,166.0 ,180.0 ,10.0 ,961.0 ,805.0 ,28 ,13.29 \\r\\n266.0 ,112.0 ,87.0 ,178.0 ,10.0 ,910.0 ,745.0 ,28 ,39.42 \\r\\n314.0 ,145.0 ,113.0 ,179.0 ,8.0 ,869.0 ,690.0 ,28 ,46.23 \\r\\n313.0 ,145.0 ,0.0 ,127.0 ,8.0 ,1000.0 ,822.0 ,28 ,44.52 \\r\\n146.0 ,173.0 ,0.0 ,182.0 ,3.0 ,986.0 ,817.0 ,28 ,23.74 \\r\\n144.0 ,136.0 ,106.0 ,178.0 ,7.0 ,941.0 ,774.0 ,28 ,26.14 \\r\\n148.0 ,0.0 ,182.0 ,181.0 ,15.0 ,839.0 ,884.0 ,28 ,15.52 \\r\\n277.0 ,117.0 ,91.0 ,191.0 ,7.0 ,946.0 ,666.0 ,28 ,43.57 \\r\\n298.0 ,0.0 ,107.0 ,164.0 ,13.0 ,953.0 ,784.0 ,28 ,35.86 \\r\\n313.0 ,145.0 ,0.0 ,178.0 ,8.0 ,1002.0 ,689.0 ,28 ,41.05 \\r\\n155.0 ,184.0 ,143.0 ,194.0 ,9.0 ,880.0 ,699.0 ,28 ,28.99 \\r\\n289.0 ,134.0 ,0.0 ,195.0 ,6.0 ,924.0 ,760.0 ,28 ,46.24 \\r\\n148.0 ,175.0 ,0.0 ,171.0 ,2.0 ,1000.0 ,828.0 ,28 ,26.92 \\r\\n145.0 ,0.0 ,179.0 ,202.0 ,8.0 ,824.0 ,869.0 ,28 ,10.54 \\r\\n313.0 ,0.0 ,0.0 ,178.0 ,8.0 ,1000.0 ,822.0 ,28 ,25.10 \\r\\n136.0 ,162.0 ,126.0 ,172.0 ,10.0 ,923.0 ,764.0 ,28 ,29.07 \\r\\n155.0 ,0.0 ,143.0 ,193.0 ,9.0 ,877.0 ,868.0 ,28 ,9.74 \\r\\n255.0 ,99.0 ,77.0 ,189.0 ,6.0 ,919.0 ,749.0 ,28 ,33.80 \\r\\n162.0 ,207.0 ,172.0 ,216.0 ,10.0 ,822.0 ,638.0 ,28 ,39.84 \\r\\n136.0 ,196.0 ,98.0 ,199.0 ,6.0 ,847.0 ,783.0 ,28 ,26.97 \\r\\n164.0 ,163.0 ,128.0 ,197.0 ,8.0 ,961.0 ,641.0 ,28 ,27.23 \\r\\n162.0 ,214.0 ,164.0 ,202.0 ,10.0 ,820.0 ,680.0 ,28 ,30.65 \\r\\n157.0 ,214.0 ,152.0 ,200.0 ,9.0 ,819.0 ,704.0 ,28 ,33.05 \\r\\n149.0 ,153.0 ,194.0 ,192.0 ,8.0 ,935.0 ,623.0 ,28 ,24.58 \\r\\n135.0 ,105.0 ,193.0 ,196.0 ,6.0 ,965.0 ,643.0 ,28 ,21.91 \\r\\n159.0 ,209.0 ,161.0 ,201.0 ,7.0 ,848.0 ,669.0 ,28 ,30.88 \\r\\n144.0 ,15.0 ,195.0 ,176.0 ,6.0 ,1021.0 ,709.0 ,28 ,15.34 \\r\\n154.0 ,174.0 ,185.0 ,228.0 ,7.0 ,845.0 ,612.0 ,28 ,24.34 \\r\\n167.0 ,187.0 ,195.0 ,185.0 ,7.0 ,898.0 ,636.0 ,28 ,23.89 \\r\\n184.0 ,86.0 ,190.0 ,213.0 ,6.0 ,923.0 ,623.0 ,28 ,22.93 \\r\\n156.0 ,178.0 ,187.0 ,221.0 ,7.0 ,854.0 ,614.0 ,28 ,29.41 \\r\\n236.9 ,91.7 ,71.5 ,246.9 ,6.0 ,852.9 ,695.4 ,28 ,28.63 \\r\\n313.3 ,0.0 ,113.0 ,178.5 ,8.0 ,1001.9 ,688.7 ,28 ,36.80 \\r\\n154.8 ,183.4 ,0.0 ,193.3 ,9.1 ,1047.4 ,696.7 ,28 ,18.29 \\r\\n145.9 ,230.5 ,0.0 ,202.5 ,3.4 ,827.0 ,871.8 ,28 ,32.72 \\r\\n296.0 ,0.0 ,106.7 ,221.4 ,10.5 ,819.2 ,778.4 ,28 ,31.42 \\r\\n133.1 ,210.2 ,0.0 ,195.7 ,3.1 ,949.4 ,795.3 ,28 ,28.94 \\r\\n313.3 ,145.0 ,0.0 ,178.5 ,8.0 ,867.2 ,824.0 ,28 ,40.93 \\r\\n151.6 ,0.0 ,111.9 ,184.4 ,7.9 ,992.0 ,815.9 ,28 ,12.18 \\r\\n153.1 ,145.0 ,113.0 ,178.5 ,8.0 ,1001.9 ,688.7 ,28 ,25.56 \\r\\n139.9 ,132.6 ,103.3 ,200.3 ,7.4 ,916.0 ,753.4 ,28 ,36.44 \\r\\n149.5 ,236.0 ,0.0 ,175.8 ,12.6 ,846.8 ,892.7 ,28 ,32.96 \\r\\n299.8 ,0.0 ,119.8 ,211.5 ,9.9 ,878.2 ,727.6 ,28 ,23.84 \\r\\n153.1 ,145.0 ,113.0 ,178.5 ,8.0 ,867.2 ,824.0 ,28 ,26.23 \\r\\n148.1 ,0.0 ,136.6 ,158.1 ,16.1 ,1001.8 ,830.1 ,28 ,17.96 \\r\\n326.5 ,0.0 ,137.9 ,199.0 ,10.8 ,801.1 ,792.5 ,28 ,38.63 \\r\\n152.7 ,144.7 ,0.0 ,178.1 ,8.0 ,999.7 ,822.2 ,28 ,19.01 \\r\\n261.9 ,110.5 ,86.1 ,195.4 ,5.0 ,895.2 ,732.6 ,28 ,33.72 \\r\\n158.4 ,0.0 ,194.9 ,219.7 ,11.0 ,897.7 ,712.9 ,28 ,8.54 \\r\\n150.7 ,0.0 ,185.3 ,166.7 ,15.6 ,1074.5 ,678.0 ,28 ,13.46 \\r\\n272.6 ,0.0 ,89.6 ,198.7 ,10.6 ,931.3 ,762.2 ,28 ,32.25 \\r\\n149.0 ,117.6 ,91.7 ,182.9 ,7.1 ,953.4 ,780.3 ,28 ,23.52 \\r\\n143.0 ,169.4 ,142.7 ,190.7 ,8.4 ,967.4 ,643.5 ,28 ,29.73 \\r\\n259.9 ,100.6 ,78.4 ,170.6 ,10.4 ,935.7 ,762.9 ,28 ,49.77 \\r\\n312.9 ,160.5 ,0.0 ,177.6 ,9.6 ,916.6 ,759.5 ,28 ,52.45 \\r\\n284.0 ,119.7 ,0.0 ,168.3 ,7.2 ,970.4 ,794.2 ,28 ,40.93 \\r\\n336.5 ,0.0 ,0.0 ,181.9 ,3.4 ,985.8 ,816.8 ,28 ,44.87 \\r\\n144.8 ,0.0 ,133.6 ,180.8 ,11.1 ,979.5 ,811.5 ,28 ,13.20 \\r\\n150.0 ,236.8 ,0.0 ,173.8 ,11.9 ,1069.3 ,674.8 ,28 ,37.43 \\r\\n143.7 ,170.2 ,132.6 ,191.6 ,8.5 ,814.1 ,805.3 ,28 ,29.87 \\r\\n330.5 ,169.6 ,0.0 ,194.9 ,8.1 ,811.0 ,802.3 ,28 ,56.62 \\r\\n154.8 ,0.0 ,142.8 ,193.3 ,9.1 ,1047.4 ,696.7 ,28 ,12.46 \\r\\n154.8 ,183.4 ,0.0 ,193.3 ,9.1 ,877.2 ,867.7 ,28 ,23.79 \\r\\n134.7 ,0.0 ,165.7 ,180.2 ,10.0 ,961.0 ,804.9 ,28 ,13.29 \\r\\n266.2 ,112.3 ,87.5 ,177.9 ,10.4 ,909.7 ,744.5 ,28 ,39.42 \\r\\n314.0 ,145.3 ,113.2 ,178.9 ,8.0 ,869.1 ,690.2 ,28 ,46.23 \\r\\n312.7 ,144.7 ,0.0 ,127.3 ,8.0 ,999.7 ,822.2 ,28 ,44.52 \\r\\n145.7 ,172.6 ,0.0 ,181.9 ,3.4 ,985.8 ,816.8 ,28 ,23.74 \\r\\n143.8 ,136.3 ,106.2 ,178.1 ,7.5 ,941.5 ,774.3 ,28 ,26.15 \\r\\n148.1 ,0.0 ,182.1 ,181.4 ,15.0 ,838.9 ,884.3 ,28 ,15.53 \\r\\n277.0 ,116.8 ,91.0 ,190.6 ,7.0 ,946.5 ,665.6 ,28 ,43.58 \\r\\n298.1 ,0.0 ,107.5 ,163.6 ,12.8 ,953.2 ,784.0 ,28 ,35.87 \\r\\n313.3 ,145.0 ,0.0 ,178.5 ,8.0 ,1001.9 ,688.7 ,28 ,41.05 \\r\\n155.2 ,183.9 ,143.2 ,193.8 ,9.2 ,879.6 ,698.5 ,28 ,28.99 \\r\\n289.0 ,133.7 ,0.0 ,194.9 ,5.5 ,924.1 ,760.1 ,28 ,46.25 \\r\\n147.8 ,175.1 ,0.0 ,171.2 ,2.2 ,1000.0 ,828.5 ,28 ,26.92 \\r\\n145.4 ,0.0 ,178.9 ,201.7 ,7.8 ,824.0 ,868.7 ,28 ,10.54 \\r\\n312.7 ,0.0 ,0.0 ,178.1 ,8.0 ,999.7 ,822.2 ,28 ,25.10 \\r\\n136.4 ,161.6 ,125.8 ,171.6 ,10.4 ,922.6 ,764.4 ,28 ,29.07 \\r\\n154.8 ,0.0 ,142.8 ,193.3 ,9.1 ,877.2 ,867.7 ,28 ,9.74 \\r\\n255.3 ,98.8 ,77.0 ,188.6 ,6.5 ,919.0 ,749.3 ,28 ,33.80 \\r\\n272.8 ,105.1 ,81.8 ,209.7 ,9.0 ,904.0 ,679.7 ,28 ,37.17 \\r\\n162.0 ,190.1 ,148.1 ,178.8 ,18.8 ,838.1 ,741.4 ,28 ,33.76 \\r\\n153.6 ,144.2 ,112.3 ,220.1 ,10.1 ,923.2 ,657.9 ,28 ,16.50 \\r\\n146.5 ,114.6 ,89.3 ,201.9 ,8.8 ,860.0 ,829.5 ,28 ,19.99 \\r\\n151.8 ,178.1 ,138.7 ,167.5 ,18.3 ,944.0 ,694.6 ,28 ,36.35 \\r\\n309.9 ,142.8 ,111.2 ,167.8 ,22.1 ,913.9 ,651.2 ,28 ,38.22 \\r\\n143.6 ,0.0 ,174.9 ,158.4 ,17.9 ,942.7 ,844.5 ,28 ,15.42 \\r\\n303.6 ,139.9 ,0.0 ,213.5 ,6.2 ,895.5 ,722.5 ,28 ,33.42 \\r\\n374.3 ,0.0 ,0.0 ,190.2 ,6.7 ,1013.2 ,730.4 ,28 ,39.06 \\r\\n158.6 ,148.9 ,116.0 ,175.1 ,15.0 ,953.3 ,719.7 ,28 ,27.68 \\r\\n152.6 ,238.7 ,0.0 ,200.0 ,6.3 ,1001.8 ,683.9 ,28 ,26.86 \\r\\n310.0 ,142.8 ,0.0 ,167.9 ,10.0 ,914.3 ,804.0 ,28 ,45.30 \\r\\n304.8 ,0.0 ,99.6 ,196.0 ,9.8 ,959.4 ,705.2 ,28 ,30.12 \\r\\n150.9 ,0.0 ,183.9 ,166.6 ,11.6 ,991.2 ,772.2 ,28 ,15.57 \\r\\n141.9 ,166.6 ,129.7 ,173.5 ,10.9 ,882.6 ,785.3 ,28 ,44.61 \\r\\n297.8 ,137.2 ,106.9 ,201.3 ,6.0 ,878.4 ,655.3 ,28 ,53.52 \\r\\n321.3 ,164.2 ,0.0 ,190.5 ,4.6 ,870.0 ,774.0 ,28 ,57.22 \\r\\n366.0 ,187.0 ,0.0 ,191.3 ,6.6 ,824.3 ,756.9 ,28 ,65.91 \\r\\n279.8 ,128.9 ,100.4 ,172.4 ,9.5 ,825.1 ,804.9 ,28 ,52.83 \\r\\n252.1 ,97.1 ,75.6 ,193.8 ,8.3 ,835.5 ,821.4 ,28 ,33.40 \\r\\n164.6 ,0.0 ,150.4 ,181.6 ,11.7 ,1023.3 ,728.9 ,28 ,18.03 \\r\\n155.6 ,243.5 ,0.0 ,180.3 ,10.7 ,1022.0 ,697.7 ,28 ,37.36 \\r\\n160.2 ,188.0 ,146.4 ,203.2 ,11.3 ,828.7 ,709.7 ,28 ,35.31 \\r\\n298.1 ,0.0 ,107.0 ,186.4 ,6.1 ,879.0 ,815.2 ,28 ,42.64 \\r\\n317.9 ,0.0 ,126.5 ,209.7 ,5.7 ,860.5 ,736.6 ,28 ,40.06 \\r\\n287.3 ,120.5 ,93.9 ,187.6 ,9.2 ,904.4 ,695.9 ,28 ,43.80 \\r\\n325.6 ,166.4 ,0.0 ,174.0 ,8.9 ,881.6 ,790.0 ,28 ,61.24 \\r\\n355.9 ,0.0 ,141.6 ,193.3 ,11.0 ,801.4 ,778.4 ,28 ,40.87 \\r\\n132.0 ,206.5 ,160.9 ,178.9 ,5.5 ,866.9 ,735.6 ,28 ,33.31 \\r\\n322.5 ,148.6 ,0.0 ,185.8 ,8.5 ,951.0 ,709.5 ,28 ,52.43 \\r\\n164.2 ,0.0 ,200.1 ,181.2 ,12.6 ,849.3 ,846.0 ,28 ,15.09 \\r\\n313.8 ,0.0 ,112.6 ,169.9 ,10.1 ,925.3 ,782.9 ,28 ,38.46 \\r\\n321.4 ,0.0 ,127.9 ,182.5 ,11.5 ,870.1 ,779.7 ,28 ,37.27 \\r\\n139.7 ,163.9 ,127.7 ,236.7 ,5.8 ,868.6 ,655.6 ,28 ,35.23 \\r\\n288.4 ,121.0 ,0.0 ,177.4 ,7.0 ,907.9 ,829.5 ,28 ,42.14 \\r\\n298.2 ,0.0 ,107.0 ,209.7 ,11.1 ,879.6 ,744.2 ,28 ,31.88 \\r\\n264.5 ,111.0 ,86.5 ,195.5 ,5.9 ,832.6 ,790.4 ,28 ,41.54 \\r\\n159.8 ,250.0 ,0.0 ,168.4 ,12.2 ,1049.3 ,688.2 ,28 ,39.46 \\r\\n166.0 ,259.7 ,0.0 ,183.2 ,12.7 ,858.8 ,826.8 ,28 ,37.92 \\r\\n276.4 ,116.0 ,90.3 ,179.6 ,8.9 ,870.1 ,768.3 ,28 ,44.28 \\r\\n322.2 ,0.0 ,115.6 ,196.0 ,10.4 ,817.9 ,813.4 ,28 ,31.18 \\r\\n148.5 ,139.4 ,108.6 ,192.7 ,6.1 ,892.4 ,780.0 ,28 ,23.70 \\r\\n159.1 ,186.7 ,0.0 ,175.6 ,11.3 ,989.6 ,788.9 ,28 ,32.77 \\r\\n260.9 ,100.5 ,78.3 ,200.6 ,8.6 ,864.5 ,761.5 ,28 ,32.40 '}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "con_data= pd.read_csv(\"concrete_data.csv\")\n",
        "con_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XgV0mkXKBHNT",
        "outputId": "e26904d5-d693-4cd8-d973-da9460beb7bc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "0   540.0                 0.0      0.0  162.0               2.5   \n",
              "1   540.0                 0.0      0.0  162.0               2.5   \n",
              "2   332.5               142.5      0.0  228.0               0.0   \n",
              "3   332.5               142.5      0.0  228.0               0.0   \n",
              "4   198.6               132.4      0.0  192.0               0.0   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
              "0            1040.0           676.0   28     79.99  \n",
              "1            1055.0           676.0   28     61.89  \n",
              "2             932.0           594.0  270     40.27  \n",
              "3             932.0           594.0  365     41.05  \n",
              "4             978.4           825.5  360     44.30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c66fe85-6529-432a-88a1-3816b192703a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c66fe85-6529-432a-88a1-3816b192703a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c66fe85-6529-432a-88a1-3816b192703a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c66fe85-6529-432a-88a1-3816b192703a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c023c88-e5a1-4577-8f1f-2909718eef15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c023c88-e5a1-4577-8f1f-2909718eef15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c023c88-e5a1-4577-8f1f-2909718eef15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "con_data",
              "summary": "{\n  \"name\": \"con_data\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.50636449481532,\n        \"min\": 102.0,\n        \"max\": 540.0,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          337.9,\n          290.2,\n          262.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.27934174810584,\n        \"min\": 0.0,\n        \"max\": 359.4,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          94.7,\n          119.0,\n          136.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.99700415268765,\n        \"min\": 0.0,\n        \"max\": 200.1,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          98.0,\n          142.0,\n          195.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.35421856503247,\n        \"min\": 121.8,\n        \"max\": 247.0,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          195.4,\n          183.8,\n          127.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.97384139248552,\n        \"min\": 0.0,\n        \"max\": 32.2,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          15.0,\n          28.2,\n          16.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.75395396672077,\n        \"min\": 801.0,\n        \"max\": 1145.0,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          852.1,\n          913.9,\n          914.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.17598014240437,\n        \"min\": 594.0,\n        \"max\": 992.6,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          710.0,\n          695.4,\n          769.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63,\n        \"min\": 1,\n        \"max\": 365,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          91,\n          100,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.705741961912512,\n        \"min\": 2.33,\n        \"max\": 82.6,\n        \"num_unique_values\": 845,\n        \"samples\": [\n          41.68,\n          39.59,\n          2.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*When using pd.read_csv(\"concrete_data.csv\"), we're leveraging the power of Pandas to load data from a CSV file named 'concrete_data.csv'. This operation creates a DataFrame, a tabular data structure, which enables us to explore, preprocess, and analyze the data efficiently. It's a crucial step in any data science or machine learning project, allowing us to work with structured data seamlessly.*"
      ],
      "metadata": {
        "id": "uGWTBWEBO_3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "con_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uE5rXXQBXHH",
        "outputId": "06e3f812-98c2-4495-89ee-c406de252fb7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1030, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "con_data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "71NazG6pBrzw",
        "outputId": "558c3556-d1d5-46ec-adeb-34d73d1b5b6c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
              "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
              "mean    281.167864           73.895825    54.188350   181.567282   \n",
              "std     104.506364           86.279342    63.997004    21.354219   \n",
              "min     102.000000            0.000000     0.000000   121.800000   \n",
              "25%     192.375000            0.000000     0.000000   164.900000   \n",
              "50%     272.900000           22.000000     0.000000   185.000000   \n",
              "75%     350.000000          142.950000   118.300000   192.000000   \n",
              "max     540.000000          359.400000   200.100000   247.000000   \n",
              "\n",
              "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
              "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
              "mean           6.204660        972.918932      773.580485    45.662136   \n",
              "std            5.973841         77.753954       80.175980    63.169912   \n",
              "min            0.000000        801.000000      594.000000     1.000000   \n",
              "25%            0.000000        932.000000      730.950000     7.000000   \n",
              "50%            6.400000        968.000000      779.500000    28.000000   \n",
              "75%           10.200000       1029.400000      824.000000    56.000000   \n",
              "max           32.200000       1145.000000      992.600000   365.000000   \n",
              "\n",
              "          Strength  \n",
              "count  1030.000000  \n",
              "mean     35.817961  \n",
              "std      16.705742  \n",
              "min       2.330000  \n",
              "25%      23.710000  \n",
              "50%      34.445000  \n",
              "75%      46.135000  \n",
              "max      82.600000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26086508-0b60-440f-b984-494a6ab3f013\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>281.167864</td>\n",
              "      <td>73.895825</td>\n",
              "      <td>54.188350</td>\n",
              "      <td>181.567282</td>\n",
              "      <td>6.204660</td>\n",
              "      <td>972.918932</td>\n",
              "      <td>773.580485</td>\n",
              "      <td>45.662136</td>\n",
              "      <td>35.817961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>104.506364</td>\n",
              "      <td>86.279342</td>\n",
              "      <td>63.997004</td>\n",
              "      <td>21.354219</td>\n",
              "      <td>5.973841</td>\n",
              "      <td>77.753954</td>\n",
              "      <td>80.175980</td>\n",
              "      <td>63.169912</td>\n",
              "      <td>16.705742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>121.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>594.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>192.375000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>164.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>932.000000</td>\n",
              "      <td>730.950000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>23.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>272.900000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>968.000000</td>\n",
              "      <td>779.500000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>34.445000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>350.000000</td>\n",
              "      <td>142.950000</td>\n",
              "      <td>118.300000</td>\n",
              "      <td>192.000000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>1029.400000</td>\n",
              "      <td>824.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>46.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>540.000000</td>\n",
              "      <td>359.400000</td>\n",
              "      <td>200.100000</td>\n",
              "      <td>247.000000</td>\n",
              "      <td>32.200000</td>\n",
              "      <td>1145.000000</td>\n",
              "      <td>992.600000</td>\n",
              "      <td>365.000000</td>\n",
              "      <td>82.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26086508-0b60-440f-b984-494a6ab3f013')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-26086508-0b60-440f-b984-494a6ab3f013 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-26086508-0b60-440f-b984-494a6ab3f013');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf78a4bf-6f9b-47b6-8984-acd71a94ff08\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf78a4bf-6f9b-47b6-8984-acd71a94ff08')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf78a4bf-6f9b-47b6-8984-acd71a94ff08 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"con_data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 305.925723919693,\n        \"min\": 102.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          281.16786407766995,\n          272.9,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 349.7840582355622,\n        \"min\": 0.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1030.0,\n          73.89582524271846,\n          142.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 349.10248573300066,\n        \"min\": 0.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1030.0,\n          54.18834951456311,\n          200.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 314.8829234606696,\n        \"min\": 21.35421856503247,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          181.56728155339806,\n          185.0,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 361.22346926276094,\n        \"min\": 0.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1030.0,\n          6.204660194174758,\n          10.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334.4689898607596,\n        \"min\": 77.75395396672077,\n        \"max\": 1145.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          972.9189320388349,\n          968.0,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 295.86618714901516,\n        \"min\": 80.17598014240437,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          773.5804854368932,\n          779.5,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 355.7357522307611,\n        \"min\": 1.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          45.662135922330094,\n          28.0,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 352.74449506712654,\n        \"min\": 2.33,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          35.817961165048544,\n          34.445,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we have detailed look on the above, we will get how much features have impact on the prediction of data.Let we break down one by one.\n",
        "\n",
        "**Cement:** The dataset contains cement content ranging from 102 kg/m³ to 540 kg/m³, with an average of approximately 281.17 kg/m³. The distribution appears to be slightly positively skewed, with a relatively wide spread of values around the mean.\n",
        "\n",
        "**Blast Furnace Slag:** The blast furnace slag content varies from 0 kg/m³ to 359.4 kg/m³, with an average of approximately 73.90 kg/m³. There is considerable variability in slag content, as indicated by the standard deviation of approximately 86.28 kg/m³.\n",
        "\n",
        "**Fly Ash:** Fly ash content ranges from 0 kg/m³ to 200.1 kg/m³, with an average of approximately 54.19 kg/m³. The distribution appears to be positively skewed, with a wide spread of values.\n",
        "\n",
        "**Water:** Water content varies from 121.8 kg/m³ to 247 kg/m³, with an average of approximately 181.57 kg/m³. The distribution appears to be relatively symmetric, with a standard deviation of approximately 21.35 kg/m³.\n",
        "\n",
        "**Superplasticizer:** Superplasticizer content ranges from 0 kg/m³ to 32.2 kg/m³, with an average of approximately 6.20 kg/m³. There is notable variability in superplasticizer content, as indicated by the standard deviation of approximately 5.97 kg/m³.\n",
        "\n",
        "**Coarse Aggregate:** The dataset contains coarse aggregate content ranging from 801 kg/m³ to 1145 kg/m³, with an average of approximately 972.92 kg/m³. The distribution appears to be relatively symmetric, with a standard deviation of approximately 77.75 kg/m³.\n",
        "\n",
        "**Fine Aggregate:** Fine aggregate content varies from 594 kg/m³ to 992.6 kg/m³, with an average of approximately 773.58 kg/m³. The distribution appears to be relatively symmetric, with a standard deviation of approximately 80.18 kg/m³.\n",
        "\n",
        "**Age:** The age of the concrete samples ranges from 1 day to 365 days, with an average of approximately 45.66 days. There is considerable variability in the age of the samples, as indicated by the standard deviation of approximately 63.17 days.\n",
        "\n",
        "**Strength:** The compressive strength of the concrete samples varies from 2.33 MPa to 82.6 MPa, with an average of approximately 35.82 MPa. The distribution appears to be positively skewed, with a wide spread of values."
      ],
      "metadata": {
        "id": "dc9VNHxKQguT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "con_data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8ZDYug9BvCE",
        "outputId": "3bb32e2e-f9e9-48c1-dc9d-e2ecd271760f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cement                0\n",
              "Blast Furnace Slag    0\n",
              "Fly Ash               0\n",
              "Water                 0\n",
              "Superplasticizer      0\n",
              "Coarse Aggregate      0\n",
              "Fine Aggregate        0\n",
              "Age                   0\n",
              "Strength              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **isnull()** function in Pandas is used to identify missing or null values in a DataFrame. In the our data, all columns have a count of zero, indicating that there are no missing values in any of the columns. So we can move to the next step."
      ],
      "metadata": {
        "id": "mZdxRsZIR1ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "con_data_col = con_data.columns\n",
        "con_data_col"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nifSys6fB6vM",
        "outputId": "ecea8a21-d574-427b-c193-accc14c579f9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
              "       'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= con_data['Strength']\n",
        "X= con_data[con_data_col[:-1]]\n",
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAI9c0D_CM98",
        "outputId": "5889e6ea-82fb-41ef-bef8-31553440a6c4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    79.99\n",
              "1    61.89\n",
              "2    40.27\n",
              "3    41.05\n",
              "4    44.30\n",
              "Name: Strength, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu= X.mean()\n",
        "sigma= X.std()\n",
        "X_norm = (X - mu) / sigma\n",
        "X_norm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bbpRF9TxDS4H",
        "outputId": "68186227-cf13-463a-803f-bdcfc7752289"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
              "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate       Age  \n",
              "0          0.862735       -1.217079 -0.279597  \n",
              "1          1.055651       -1.217079 -0.279597  \n",
              "2         -0.526262       -2.239829  3.551340  \n",
              "3         -0.526262       -2.239829  5.055221  \n",
              "4          0.070492        0.647569  4.976069  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4caa510a-9e0a-4451-a5dc-7906952da22e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>1.055651</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>3.551340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>5.055221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.790075</td>\n",
              "      <td>0.678079</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>0.488555</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>0.070492</td>\n",
              "      <td>0.647569</td>\n",
              "      <td>4.976069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4caa510a-9e0a-4451-a5dc-7906952da22e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4caa510a-9e0a-4451-a5dc-7906952da22e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4caa510a-9e0a-4451-a5dc-7906952da22e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bed36a48-cebc-4c1b-85ad-ccc2b2162131\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bed36a48-cebc-4c1b-85ad-ccc2b2162131')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bed36a48-cebc-4c1b-85ad-ccc2b2162131 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_norm",
              "summary": "{\n  \"name\": \"X_norm\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -1.7144205995851924,\n        \"max\": 2.476711702426229,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          0.5428581904707304,\n          0.08642665895030859,\n          -0.18341336597371433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -0.8564718244890963,\n        \"max\": 3.3090676049756658,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          0.24112579368094536,\n          0.5227691106981788,\n          0.7232806079985139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -0.8467325968146493,\n        \"max\": 2.2799762647844055,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          0.6845890845282162,\n          1.3721212679882784,\n          2.200285034428808\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.798851260765261,\n        \"max\": 3.064158880238681,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          0.647774509026194,\n          0.1045563170481933,\n          -2.541290911120519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -1.0386382541022239,\n        \"max\": 4.351528287732031,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          1.4723088927149754,\n          3.681942381914111,\n          1.7234036073966954\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.211063531411115,\n        \"max\": 2.213148774849662,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          -1.553862226614819,\n          -0.7590473413621567,\n          -0.7577612331335922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.239829000131109,\n        \"max\": 2.7317347935640552,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          -0.7930116391962395,\n          -0.9751110656587321,\n          -0.05338862623556972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -0.7070159638428309,\n        \"max\": 5.055221007679151,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7177129576873293,\n          0.8601858498403454,\n          -0.27959728738378287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We're making our data easier for the computer to understand. Think of it like resizing photos so they're all the same size before putting them in a photo album.*\n",
        "\n",
        "*First, we find the average and the spread of each type of data in our dataset. Then, we adjust each data point so it's centered around zero and its spread is the same for all data types. It's like adjusting the brightness and contrast of each photo so they all look consistent.*\n",
        "\n",
        "*The X_norm table shows our data after this adjustment. Now, all the numbers are in a format that's easier for the computer to work with, which can help us get better results when analyzing or predicting things from the data.*"
      ],
      "metadata": {
        "id": "2a4xSRIvT0zX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_col= X.shape[1]\n",
        "num_col"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4iGIf4eD3yC",
        "outputId": "99982a84-f94b-44a2-b591-9b21347168f3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XzORabMEEI4z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We're dividing our data into two groups: one for teaching the computer how to make predictions, and another to see how well it learned.*\n",
        "\n",
        "*First, we decide on the proportion of data we want to use for training and testing. For example, we might use 80% of the data for training and keep the remaining 20% for testing.*\n",
        "\n",
        "*Then, we use the train_test_split function to randomly split our dataset into two separate groups: the training set, which the computer will use to learn from, and the testing set, which we'll use to evaluate how well it learned.*\n",
        "\n",
        "*By doing this, we ensure that our model doesn't just memorize the data it's seen but can actually generalize to new, unseen data. This helps us assess its real-world performance accurately.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XPw-7CTWUKbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple Regression Model**"
      ],
      "metadata": {
        "id": "b-cY6SU0JroX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define regression model\n",
        "def regression_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='relu', input_shape=(num_col,)))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "f-ubAipMGG7n"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d02d1ac4-d56b-4879-ab94-9c156f690bbf"
      },
      "outputs": [],
      "source": [
        "# build the model\n",
        "model_1 = regression_model()"
      ],
      "execution_count": 39
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ebe5f26-9a52-4506-a777-b651608e3840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780263fd-e076-4a49-a6cf-6e43cd92bc40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "18/18 - 1s - loss: 452.2123 - val_loss: 166.9998 - 948ms/epoch - 53ms/step\n",
            "Epoch 2/100\n",
            "18/18 - 0s - loss: 151.6327 - val_loss: 145.9667 - 66ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "18/18 - 0s - loss: 125.0924 - val_loss: 107.0759 - 67ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "18/18 - 0s - loss: 114.4568 - val_loss: 112.4039 - 81ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "18/18 - 0s - loss: 104.9550 - val_loss: 105.7808 - 66ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "18/18 - 0s - loss: 99.9979 - val_loss: 92.0430 - 75ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "18/18 - 0s - loss: 92.2044 - val_loss: 85.7608 - 69ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "18/18 - 0s - loss: 89.8362 - val_loss: 95.4625 - 80ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "18/18 - 0s - loss: 90.9148 - val_loss: 89.8677 - 79ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "18/18 - 0s - loss: 84.3872 - val_loss: 96.8057 - 74ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "18/18 - 0s - loss: 83.7689 - val_loss: 80.7208 - 75ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "18/18 - 0s - loss: 78.6638 - val_loss: 105.4133 - 76ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "18/18 - 0s - loss: 81.6116 - val_loss: 110.6686 - 78ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "18/18 - 0s - loss: 83.5928 - val_loss: 73.1088 - 83ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "18/18 - 0s - loss: 78.3357 - val_loss: 66.5552 - 79ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "18/18 - 0s - loss: 71.7552 - val_loss: 72.3214 - 80ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "18/18 - 0s - loss: 72.1581 - val_loss: 67.3442 - 81ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "18/18 - 0s - loss: 75.9559 - val_loss: 77.8839 - 79ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "18/18 - 0s - loss: 71.6095 - val_loss: 60.5726 - 153ms/epoch - 8ms/step\n",
            "Epoch 20/100\n",
            "18/18 - 0s - loss: 72.6173 - val_loss: 62.6763 - 104ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "18/18 - 0s - loss: 70.3668 - val_loss: 64.7297 - 119ms/epoch - 7ms/step\n",
            "Epoch 22/100\n",
            "18/18 - 0s - loss: 68.2644 - val_loss: 56.8598 - 97ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "18/18 - 0s - loss: 68.6953 - val_loss: 80.3937 - 105ms/epoch - 6ms/step\n",
            "Epoch 24/100\n",
            "18/18 - 0s - loss: 67.6209 - val_loss: 58.8030 - 95ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "18/18 - 0s - loss: 59.4544 - val_loss: 54.5680 - 95ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "18/18 - 0s - loss: 58.1259 - val_loss: 54.6233 - 99ms/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "18/18 - 0s - loss: 64.0400 - val_loss: 63.7794 - 113ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "18/18 - 0s - loss: 69.9827 - val_loss: 81.8389 - 83ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "18/18 - 0s - loss: 69.1122 - val_loss: 51.6412 - 81ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "18/18 - 0s - loss: 66.6537 - val_loss: 69.4829 - 92ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "18/18 - 0s - loss: 60.5254 - val_loss: 57.0773 - 85ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "18/18 - 0s - loss: 63.2933 - val_loss: 51.3632 - 83ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "18/18 - 0s - loss: 60.9701 - val_loss: 75.4750 - 90ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "18/18 - 0s - loss: 58.9019 - val_loss: 84.1121 - 156ms/epoch - 9ms/step\n",
            "Epoch 35/100\n",
            "18/18 - 0s - loss: 66.4240 - val_loss: 48.0722 - 112ms/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "18/18 - 0s - loss: 56.3645 - val_loss: 46.3548 - 105ms/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "18/18 - 0s - loss: 53.1535 - val_loss: 69.5389 - 114ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "18/18 - 0s - loss: 58.6166 - val_loss: 47.7778 - 147ms/epoch - 8ms/step\n",
            "Epoch 39/100\n",
            "18/18 - 0s - loss: 53.8019 - val_loss: 50.6833 - 102ms/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "18/18 - 0s - loss: 51.0880 - val_loss: 46.1629 - 99ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "18/18 - 0s - loss: 56.8295 - val_loss: 59.4251 - 107ms/epoch - 6ms/step\n",
            "Epoch 42/100\n",
            "18/18 - 0s - loss: 52.6658 - val_loss: 57.7889 - 105ms/epoch - 6ms/step\n",
            "Epoch 43/100\n",
            "18/18 - 0s - loss: 64.7894 - val_loss: 49.0449 - 78ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "18/18 - 0s - loss: 54.0761 - val_loss: 61.5754 - 71ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "18/18 - 0s - loss: 53.9837 - val_loss: 50.2198 - 76ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "18/18 - 0s - loss: 54.6840 - val_loss: 55.2656 - 65ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "18/18 - 0s - loss: 49.4223 - val_loss: 45.1655 - 80ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "18/18 - 0s - loss: 47.0180 - val_loss: 48.1914 - 80ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "18/18 - 0s - loss: 50.7327 - val_loss: 48.4708 - 75ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "18/18 - 0s - loss: 55.3822 - val_loss: 55.1788 - 78ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "18/18 - 0s - loss: 48.2019 - val_loss: 44.1826 - 79ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "18/18 - 0s - loss: 49.1591 - val_loss: 41.4950 - 77ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "18/18 - 0s - loss: 51.7582 - val_loss: 50.8872 - 69ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "18/18 - 0s - loss: 65.8878 - val_loss: 42.7421 - 63ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "18/18 - 0s - loss: 48.2118 - val_loss: 40.8235 - 92ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "18/18 - 0s - loss: 47.3767 - val_loss: 46.0778 - 81ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "18/18 - 0s - loss: 52.0184 - val_loss: 44.1205 - 67ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "18/18 - 0s - loss: 51.2211 - val_loss: 51.9427 - 68ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "18/18 - 0s - loss: 54.9621 - val_loss: 72.4462 - 72ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "18/18 - 0s - loss: 51.6090 - val_loss: 41.9853 - 69ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "18/18 - 0s - loss: 50.1445 - val_loss: 41.6606 - 76ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "18/18 - 0s - loss: 51.7987 - val_loss: 41.6933 - 68ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "18/18 - 0s - loss: 60.6511 - val_loss: 41.1914 - 80ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "18/18 - 0s - loss: 46.2295 - val_loss: 41.0892 - 72ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "18/18 - 0s - loss: 45.1325 - val_loss: 43.9544 - 77ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "18/18 - 0s - loss: 45.3456 - val_loss: 42.0456 - 73ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "18/18 - 0s - loss: 44.2265 - val_loss: 38.8637 - 86ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "18/18 - 0s - loss: 44.7139 - val_loss: 46.4469 - 95ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "18/18 - 0s - loss: 51.3390 - val_loss: 73.2326 - 80ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "18/18 - 0s - loss: 56.6254 - val_loss: 50.7780 - 82ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "18/18 - 0s - loss: 46.8049 - val_loss: 42.1945 - 73ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "18/18 - 0s - loss: 48.2604 - val_loss: 51.7510 - 89ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "18/18 - 0s - loss: 45.4965 - val_loss: 47.8879 - 71ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "18/18 - 0s - loss: 42.7699 - val_loss: 38.6050 - 76ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "18/18 - 0s - loss: 43.3661 - val_loss: 54.1419 - 85ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "18/18 - 0s - loss: 50.1441 - val_loss: 41.4469 - 76ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "18/18 - 0s - loss: 46.7464 - val_loss: 41.5734 - 79ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "18/18 - 0s - loss: 42.5204 - val_loss: 48.8579 - 77ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "18/18 - 0s - loss: 44.8774 - val_loss: 37.6703 - 85ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "18/18 - 0s - loss: 45.1714 - val_loss: 48.6295 - 93ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "18/18 - 0s - loss: 44.0127 - val_loss: 42.5382 - 82ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "18/18 - 0s - loss: 54.0149 - val_loss: 43.5510 - 84ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "18/18 - 0s - loss: 46.5009 - val_loss: 60.7275 - 78ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "18/18 - 0s - loss: 41.8573 - val_loss: 40.0295 - 77ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "18/18 - 0s - loss: 42.8058 - val_loss: 38.2902 - 72ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "18/18 - 0s - loss: 44.0402 - val_loss: 37.3237 - 82ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "18/18 - 0s - loss: 38.2298 - val_loss: 37.1609 - 74ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "18/18 - 0s - loss: 37.9016 - val_loss: 60.6391 - 78ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "18/18 - 0s - loss: 42.7908 - val_loss: 44.5288 - 75ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "18/18 - 0s - loss: 46.5164 - val_loss: 49.8007 - 81ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "18/18 - 0s - loss: 55.5433 - val_loss: 66.4868 - 80ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "18/18 - 0s - loss: 47.4252 - val_loss: 44.1441 - 78ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "18/18 - 0s - loss: 39.0944 - val_loss: 36.8195 - 76ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "18/18 - 0s - loss: 37.6457 - val_loss: 37.7412 - 74ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "18/18 - 0s - loss: 36.7753 - val_loss: 38.7348 - 83ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "18/18 - 0s - loss: 37.6054 - val_loss: 36.6941 - 78ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "18/18 - 0s - loss: 52.5545 - val_loss: 43.3304 - 74ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "18/18 - 0s - loss: 43.5935 - val_loss: 39.5777 - 78ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "18/18 - 0s - loss: 39.4364 - val_loss: 42.1070 - 78ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "18/18 - 0s - loss: 36.9298 - val_loss: 43.2152 - 72ms/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f75f81beec0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# fit the model\n",
        "model_1.fit(X_train,y_train, validation_split=0.3, epochs=100, verbose=2)"
      ],
      "execution_count": 40
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We embark on an exploration of regression modeling with neural networks, a dynamic approach to predicting continuous values. Our journey begins with the definition of our model architecture encapsulated within the regression_model function. This function constructs a neural network comprising an input layer with **64 neurons**, a hidden layer with **32 neurons**, both activated by the **ReLU function**, and an output layer designed for **single-value prediction**. Once our model architecture is established, we proceed to compile it, configuring the Adam optimizer and mean squared error loss function, optimizing its performance for regression tasks. With our model compiled, we dive into training, splitting our dataset into training and validation sets, allocating 30% for validation purposes. Through 100 epochs of training, our model learns the underlying patterns within the data, guided by the mean squared error as a measure of its performance. Upon completion of training, we unleash our model's predictive prowess on the test data, generating predictions to be evaluated against ground truth values. Through the computation of the Mean Squared Error (MSE), we quantify the discrepancy between predicted and actual values, gauging the accuracy of our model's predictions. Additionally, we calculate the R-squared error, providing insight into the overall fit of our model to the data, thus concluding our journey with a comprehensive understanding of our neural network's predictive capabilities in regression tasks.*"
      ],
      "metadata": {
        "id": "6gOT_2shZ6zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred= model_1.predict(X_test)\n",
        "# Evaluate the model\n",
        "mse = model_1.evaluate(X_test, y_test, verbose=0)\n",
        "print('Mean Squared Error:', mse)\n",
        "\n",
        "# Calculate R-squared error\n",
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R-squared Error:', r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mRPXgkIGwMN",
        "outputId": "49a10068-2ff8-42c1-fb1d-d7920f4a5c73"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 2ms/step\n",
            "Mean Squared Error: 41.80687713623047\n",
            "R-squared Error: 0.8377546408769578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Based on the provided metrics, our model demonstrates relatively good performance. The Mean Squared Error (MSE) of 58.01 indicates that, on average, our predictions are within reasonable proximity to the actual values in the test dataset. Additionally, the R-squared error of 0.837 suggests that approximately 83.7% of the variance in the dependent variable is explained by the independent variables in our model. These metrics collectively indicate that our model is effective in predicting continuous values and capturing underlying patterns in the dataset, thus demonstrating its overall goodness-of-fit and suitability for the task at hand.*"
      ],
      "metadata": {
        "id": "6rJAyibnal8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define another regression model with different number of neurons in each layers\n",
        "def regression_model_2():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='relu', input_shape=(num_col,)))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# build the model\n",
        "model_11 = regression_model_2()\n",
        "\n",
        "# fit the model with 150 epochs\n",
        "model_11.fit(X_train,y_train, validation_split=0.3, epochs=150, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjyjAWhruWJ2",
        "outputId": "63e1cf82-081a-49a6-eb03-7684ac6586a6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "18/18 - 1s - loss: 1702.4402 - val_loss: 198.6868 - 1s/epoch - 61ms/step\n",
            "Epoch 2/150\n",
            "18/18 - 0s - loss: 211.5866 - val_loss: 153.6140 - 81ms/epoch - 4ms/step\n",
            "Epoch 3/150\n",
            "18/18 - 0s - loss: 169.4128 - val_loss: 136.8168 - 84ms/epoch - 5ms/step\n",
            "Epoch 4/150\n",
            "18/18 - 0s - loss: 149.3096 - val_loss: 127.7576 - 77ms/epoch - 4ms/step\n",
            "Epoch 5/150\n",
            "18/18 - 0s - loss: 135.3923 - val_loss: 114.8195 - 83ms/epoch - 5ms/step\n",
            "Epoch 6/150\n",
            "18/18 - 0s - loss: 123.7649 - val_loss: 119.8069 - 101ms/epoch - 6ms/step\n",
            "Epoch 7/150\n",
            "18/18 - 0s - loss: 118.5572 - val_loss: 101.2230 - 85ms/epoch - 5ms/step\n",
            "Epoch 8/150\n",
            "18/18 - 0s - loss: 108.0146 - val_loss: 98.1573 - 94ms/epoch - 5ms/step\n",
            "Epoch 9/150\n",
            "18/18 - 0s - loss: 101.9551 - val_loss: 92.0258 - 82ms/epoch - 5ms/step\n",
            "Epoch 10/150\n",
            "18/18 - 0s - loss: 98.8047 - val_loss: 89.5477 - 85ms/epoch - 5ms/step\n",
            "Epoch 11/150\n",
            "18/18 - 0s - loss: 98.1953 - val_loss: 88.7199 - 80ms/epoch - 4ms/step\n",
            "Epoch 12/150\n",
            "18/18 - 0s - loss: 86.9470 - val_loss: 93.6340 - 80ms/epoch - 4ms/step\n",
            "Epoch 13/150\n",
            "18/18 - 0s - loss: 99.2544 - val_loss: 133.7257 - 83ms/epoch - 5ms/step\n",
            "Epoch 14/150\n",
            "18/18 - 0s - loss: 111.9038 - val_loss: 98.7329 - 83ms/epoch - 5ms/step\n",
            "Epoch 15/150\n",
            "18/18 - 0s - loss: 89.5073 - val_loss: 68.6389 - 76ms/epoch - 4ms/step\n",
            "Epoch 16/150\n",
            "18/18 - 0s - loss: 77.3445 - val_loss: 70.4381 - 84ms/epoch - 5ms/step\n",
            "Epoch 17/150\n",
            "18/18 - 0s - loss: 76.7435 - val_loss: 65.1598 - 75ms/epoch - 4ms/step\n",
            "Epoch 18/150\n",
            "18/18 - 0s - loss: 69.6799 - val_loss: 63.6025 - 83ms/epoch - 5ms/step\n",
            "Epoch 19/150\n",
            "18/18 - 0s - loss: 76.3046 - val_loss: 62.2271 - 77ms/epoch - 4ms/step\n",
            "Epoch 20/150\n",
            "18/18 - 0s - loss: 68.3992 - val_loss: 69.6397 - 89ms/epoch - 5ms/step\n",
            "Epoch 21/150\n",
            "18/18 - 0s - loss: 64.9642 - val_loss: 59.1600 - 78ms/epoch - 4ms/step\n",
            "Epoch 22/150\n",
            "18/18 - 0s - loss: 62.1522 - val_loss: 57.4537 - 77ms/epoch - 4ms/step\n",
            "Epoch 23/150\n",
            "18/18 - 0s - loss: 58.3683 - val_loss: 57.9743 - 71ms/epoch - 4ms/step\n",
            "Epoch 24/150\n",
            "18/18 - 0s - loss: 58.8950 - val_loss: 52.7653 - 82ms/epoch - 5ms/step\n",
            "Epoch 25/150\n",
            "18/18 - 0s - loss: 63.0021 - val_loss: 79.1456 - 87ms/epoch - 5ms/step\n",
            "Epoch 26/150\n",
            "18/18 - 0s - loss: 58.9493 - val_loss: 52.0269 - 121ms/epoch - 7ms/step\n",
            "Epoch 27/150\n",
            "18/18 - 0s - loss: 55.6381 - val_loss: 49.6292 - 119ms/epoch - 7ms/step\n",
            "Epoch 28/150\n",
            "18/18 - 0s - loss: 57.3689 - val_loss: 68.0787 - 117ms/epoch - 7ms/step\n",
            "Epoch 29/150\n",
            "18/18 - 0s - loss: 55.4617 - val_loss: 54.5811 - 124ms/epoch - 7ms/step\n",
            "Epoch 30/150\n",
            "18/18 - 0s - loss: 49.9813 - val_loss: 48.5999 - 113ms/epoch - 6ms/step\n",
            "Epoch 31/150\n",
            "18/18 - 0s - loss: 50.7728 - val_loss: 46.8315 - 114ms/epoch - 6ms/step\n",
            "Epoch 32/150\n",
            "18/18 - 0s - loss: 55.2833 - val_loss: 47.8754 - 106ms/epoch - 6ms/step\n",
            "Epoch 33/150\n",
            "18/18 - 0s - loss: 62.7676 - val_loss: 45.6580 - 105ms/epoch - 6ms/step\n",
            "Epoch 34/150\n",
            "18/18 - 0s - loss: 51.4819 - val_loss: 44.4690 - 119ms/epoch - 7ms/step\n",
            "Epoch 35/150\n",
            "18/18 - 0s - loss: 52.1079 - val_loss: 45.7725 - 104ms/epoch - 6ms/step\n",
            "Epoch 36/150\n",
            "18/18 - 0s - loss: 49.7225 - val_loss: 52.1164 - 109ms/epoch - 6ms/step\n",
            "Epoch 37/150\n",
            "18/18 - 0s - loss: 49.5920 - val_loss: 42.3591 - 125ms/epoch - 7ms/step\n",
            "Epoch 38/150\n",
            "18/18 - 0s - loss: 48.0552 - val_loss: 54.5660 - 167ms/epoch - 9ms/step\n",
            "Epoch 39/150\n",
            "18/18 - 0s - loss: 53.0252 - val_loss: 47.1503 - 117ms/epoch - 6ms/step\n",
            "Epoch 40/150\n",
            "18/18 - 0s - loss: 48.4045 - val_loss: 44.1577 - 98ms/epoch - 5ms/step\n",
            "Epoch 41/150\n",
            "18/18 - 0s - loss: 42.4494 - val_loss: 42.4703 - 102ms/epoch - 6ms/step\n",
            "Epoch 42/150\n",
            "18/18 - 0s - loss: 43.7970 - val_loss: 45.5744 - 151ms/epoch - 8ms/step\n",
            "Epoch 43/150\n",
            "18/18 - 0s - loss: 43.4011 - val_loss: 60.2666 - 125ms/epoch - 7ms/step\n",
            "Epoch 44/150\n",
            "18/18 - 0s - loss: 47.6042 - val_loss: 54.2846 - 124ms/epoch - 7ms/step\n",
            "Epoch 45/150\n",
            "18/18 - 0s - loss: 52.5551 - val_loss: 46.3884 - 121ms/epoch - 7ms/step\n",
            "Epoch 46/150\n",
            "18/18 - 0s - loss: 57.2259 - val_loss: 65.6823 - 101ms/epoch - 6ms/step\n",
            "Epoch 47/150\n",
            "18/18 - 0s - loss: 44.8870 - val_loss: 42.3141 - 97ms/epoch - 5ms/step\n",
            "Epoch 48/150\n",
            "18/18 - 0s - loss: 42.3878 - val_loss: 47.5747 - 89ms/epoch - 5ms/step\n",
            "Epoch 49/150\n",
            "18/18 - 0s - loss: 39.8259 - val_loss: 42.9931 - 77ms/epoch - 4ms/step\n",
            "Epoch 50/150\n",
            "18/18 - 0s - loss: 42.4837 - val_loss: 39.6130 - 87ms/epoch - 5ms/step\n",
            "Epoch 51/150\n",
            "18/18 - 0s - loss: 46.1274 - val_loss: 50.4147 - 86ms/epoch - 5ms/step\n",
            "Epoch 52/150\n",
            "18/18 - 0s - loss: 48.8632 - val_loss: 39.9119 - 74ms/epoch - 4ms/step\n",
            "Epoch 53/150\n",
            "18/18 - 0s - loss: 46.9469 - val_loss: 45.7226 - 73ms/epoch - 4ms/step\n",
            "Epoch 54/150\n",
            "18/18 - 0s - loss: 41.3961 - val_loss: 42.9534 - 75ms/epoch - 4ms/step\n",
            "Epoch 55/150\n",
            "18/18 - 0s - loss: 40.5070 - val_loss: 39.2839 - 89ms/epoch - 5ms/step\n",
            "Epoch 56/150\n",
            "18/18 - 0s - loss: 48.1629 - val_loss: 46.2754 - 82ms/epoch - 5ms/step\n",
            "Epoch 57/150\n",
            "18/18 - 0s - loss: 56.5946 - val_loss: 63.4914 - 80ms/epoch - 4ms/step\n",
            "Epoch 58/150\n",
            "18/18 - 0s - loss: 48.8206 - val_loss: 38.8753 - 131ms/epoch - 7ms/step\n",
            "Epoch 59/150\n",
            "18/18 - 0s - loss: 41.7188 - val_loss: 39.9288 - 79ms/epoch - 4ms/step\n",
            "Epoch 60/150\n",
            "18/18 - 0s - loss: 38.9324 - val_loss: 43.8332 - 82ms/epoch - 5ms/step\n",
            "Epoch 61/150\n",
            "18/18 - 0s - loss: 42.7011 - val_loss: 43.0190 - 82ms/epoch - 5ms/step\n",
            "Epoch 62/150\n",
            "18/18 - 0s - loss: 40.7129 - val_loss: 47.2275 - 70ms/epoch - 4ms/step\n",
            "Epoch 63/150\n",
            "18/18 - 0s - loss: 51.5915 - val_loss: 58.7368 - 79ms/epoch - 4ms/step\n",
            "Epoch 64/150\n",
            "18/18 - 0s - loss: 58.6832 - val_loss: 61.1556 - 78ms/epoch - 4ms/step\n",
            "Epoch 65/150\n",
            "18/18 - 0s - loss: 59.6259 - val_loss: 43.2746 - 90ms/epoch - 5ms/step\n",
            "Epoch 66/150\n",
            "18/18 - 0s - loss: 63.3602 - val_loss: 43.1980 - 81ms/epoch - 4ms/step\n",
            "Epoch 67/150\n",
            "18/18 - 0s - loss: 53.4379 - val_loss: 38.8974 - 78ms/epoch - 4ms/step\n",
            "Epoch 68/150\n",
            "18/18 - 0s - loss: 52.6033 - val_loss: 43.3015 - 90ms/epoch - 5ms/step\n",
            "Epoch 69/150\n",
            "18/18 - 0s - loss: 43.8054 - val_loss: 38.3521 - 84ms/epoch - 5ms/step\n",
            "Epoch 70/150\n",
            "18/18 - 0s - loss: 40.3215 - val_loss: 38.6996 - 84ms/epoch - 5ms/step\n",
            "Epoch 71/150\n",
            "18/18 - 0s - loss: 40.9199 - val_loss: 42.9222 - 75ms/epoch - 4ms/step\n",
            "Epoch 72/150\n",
            "18/18 - 0s - loss: 39.9735 - val_loss: 40.3222 - 75ms/epoch - 4ms/step\n",
            "Epoch 73/150\n",
            "18/18 - 0s - loss: 43.1442 - val_loss: 57.7145 - 79ms/epoch - 4ms/step\n",
            "Epoch 74/150\n",
            "18/18 - 0s - loss: 44.1793 - val_loss: 37.2278 - 74ms/epoch - 4ms/step\n",
            "Epoch 75/150\n",
            "18/18 - 0s - loss: 44.4099 - val_loss: 48.5247 - 88ms/epoch - 5ms/step\n",
            "Epoch 76/150\n",
            "18/18 - 0s - loss: 41.3486 - val_loss: 44.7436 - 82ms/epoch - 5ms/step\n",
            "Epoch 77/150\n",
            "18/18 - 0s - loss: 44.4695 - val_loss: 71.3782 - 81ms/epoch - 4ms/step\n",
            "Epoch 78/150\n",
            "18/18 - 0s - loss: 39.3876 - val_loss: 43.9533 - 83ms/epoch - 5ms/step\n",
            "Epoch 79/150\n",
            "18/18 - 0s - loss: 39.7569 - val_loss: 40.3769 - 73ms/epoch - 4ms/step\n",
            "Epoch 80/150\n",
            "18/18 - 0s - loss: 38.1700 - val_loss: 40.8047 - 85ms/epoch - 5ms/step\n",
            "Epoch 81/150\n",
            "18/18 - 0s - loss: 37.3833 - val_loss: 38.3614 - 76ms/epoch - 4ms/step\n",
            "Epoch 82/150\n",
            "18/18 - 0s - loss: 34.8858 - val_loss: 38.5255 - 91ms/epoch - 5ms/step\n",
            "Epoch 83/150\n",
            "18/18 - 0s - loss: 38.3150 - val_loss: 36.9703 - 80ms/epoch - 4ms/step\n",
            "Epoch 84/150\n",
            "18/18 - 0s - loss: 37.4162 - val_loss: 38.9703 - 81ms/epoch - 5ms/step\n",
            "Epoch 85/150\n",
            "18/18 - 0s - loss: 36.8648 - val_loss: 41.3736 - 75ms/epoch - 4ms/step\n",
            "Epoch 86/150\n",
            "18/18 - 0s - loss: 36.8644 - val_loss: 45.7987 - 74ms/epoch - 4ms/step\n",
            "Epoch 87/150\n",
            "18/18 - 0s - loss: 35.7292 - val_loss: 37.0578 - 86ms/epoch - 5ms/step\n",
            "Epoch 88/150\n",
            "18/18 - 0s - loss: 37.6656 - val_loss: 47.0165 - 77ms/epoch - 4ms/step\n",
            "Epoch 89/150\n",
            "18/18 - 0s - loss: 39.8154 - val_loss: 38.7808 - 87ms/epoch - 5ms/step\n",
            "Epoch 90/150\n",
            "18/18 - 0s - loss: 37.6667 - val_loss: 39.5244 - 82ms/epoch - 5ms/step\n",
            "Epoch 91/150\n",
            "18/18 - 0s - loss: 35.3946 - val_loss: 43.7822 - 80ms/epoch - 4ms/step\n",
            "Epoch 92/150\n",
            "18/18 - 0s - loss: 38.1531 - val_loss: 37.8910 - 87ms/epoch - 5ms/step\n",
            "Epoch 93/150\n",
            "18/18 - 0s - loss: 37.4807 - val_loss: 38.7677 - 74ms/epoch - 4ms/step\n",
            "Epoch 94/150\n",
            "18/18 - 0s - loss: 36.7014 - val_loss: 39.2765 - 82ms/epoch - 5ms/step\n",
            "Epoch 95/150\n",
            "18/18 - 0s - loss: 39.8295 - val_loss: 62.9753 - 84ms/epoch - 5ms/step\n",
            "Epoch 96/150\n",
            "18/18 - 0s - loss: 45.3515 - val_loss: 37.9801 - 75ms/epoch - 4ms/step\n",
            "Epoch 97/150\n",
            "18/18 - 0s - loss: 36.2931 - val_loss: 38.6206 - 81ms/epoch - 4ms/step\n",
            "Epoch 98/150\n",
            "18/18 - 0s - loss: 33.7090 - val_loss: 40.7430 - 80ms/epoch - 4ms/step\n",
            "Epoch 99/150\n",
            "18/18 - 0s - loss: 35.4436 - val_loss: 37.5453 - 81ms/epoch - 5ms/step\n",
            "Epoch 100/150\n",
            "18/18 - 0s - loss: 36.5682 - val_loss: 35.6693 - 90ms/epoch - 5ms/step\n",
            "Epoch 101/150\n",
            "18/18 - 0s - loss: 32.3435 - val_loss: 36.4482 - 78ms/epoch - 4ms/step\n",
            "Epoch 102/150\n",
            "18/18 - 0s - loss: 33.2945 - val_loss: 40.7458 - 83ms/epoch - 5ms/step\n",
            "Epoch 103/150\n",
            "18/18 - 0s - loss: 37.1541 - val_loss: 49.4442 - 87ms/epoch - 5ms/step\n",
            "Epoch 104/150\n",
            "18/18 - 0s - loss: 38.6756 - val_loss: 37.0665 - 69ms/epoch - 4ms/step\n",
            "Epoch 105/150\n",
            "18/18 - 0s - loss: 33.7869 - val_loss: 55.3176 - 74ms/epoch - 4ms/step\n",
            "Epoch 106/150\n",
            "18/18 - 0s - loss: 35.9879 - val_loss: 40.2685 - 92ms/epoch - 5ms/step\n",
            "Epoch 107/150\n",
            "18/18 - 0s - loss: 35.0685 - val_loss: 37.1132 - 74ms/epoch - 4ms/step\n",
            "Epoch 108/150\n",
            "18/18 - 0s - loss: 36.3421 - val_loss: 41.2328 - 83ms/epoch - 5ms/step\n",
            "Epoch 109/150\n",
            "18/18 - 0s - loss: 38.3312 - val_loss: 37.5969 - 77ms/epoch - 4ms/step\n",
            "Epoch 110/150\n",
            "18/18 - 0s - loss: 33.6136 - val_loss: 43.3325 - 81ms/epoch - 4ms/step\n",
            "Epoch 111/150\n",
            "18/18 - 0s - loss: 32.5045 - val_loss: 37.1727 - 73ms/epoch - 4ms/step\n",
            "Epoch 112/150\n",
            "18/18 - 0s - loss: 37.2758 - val_loss: 43.4091 - 83ms/epoch - 5ms/step\n",
            "Epoch 113/150\n",
            "18/18 - 0s - loss: 32.3998 - val_loss: 36.2370 - 84ms/epoch - 5ms/step\n",
            "Epoch 114/150\n",
            "18/18 - 0s - loss: 32.9468 - val_loss: 44.9829 - 81ms/epoch - 4ms/step\n",
            "Epoch 115/150\n",
            "18/18 - 0s - loss: 31.3312 - val_loss: 38.7738 - 80ms/epoch - 4ms/step\n",
            "Epoch 116/150\n",
            "18/18 - 0s - loss: 35.9608 - val_loss: 52.4515 - 84ms/epoch - 5ms/step\n",
            "Epoch 117/150\n",
            "18/18 - 0s - loss: 33.6344 - val_loss: 35.0349 - 93ms/epoch - 5ms/step\n",
            "Epoch 118/150\n",
            "18/18 - 0s - loss: 32.2722 - val_loss: 36.8487 - 122ms/epoch - 7ms/step\n",
            "Epoch 119/150\n",
            "18/18 - 0s - loss: 32.4609 - val_loss: 34.9911 - 80ms/epoch - 4ms/step\n",
            "Epoch 120/150\n",
            "18/18 - 0s - loss: 38.2577 - val_loss: 36.3239 - 89ms/epoch - 5ms/step\n",
            "Epoch 121/150\n",
            "18/18 - 0s - loss: 47.9073 - val_loss: 43.0632 - 97ms/epoch - 5ms/step\n",
            "Epoch 122/150\n",
            "18/18 - 0s - loss: 37.6276 - val_loss: 35.3457 - 81ms/epoch - 4ms/step\n",
            "Epoch 123/150\n",
            "18/18 - 0s - loss: 32.5691 - val_loss: 45.5633 - 90ms/epoch - 5ms/step\n",
            "Epoch 124/150\n",
            "18/18 - 0s - loss: 33.3683 - val_loss: 34.7382 - 81ms/epoch - 5ms/step\n",
            "Epoch 125/150\n",
            "18/18 - 0s - loss: 31.7917 - val_loss: 37.5296 - 78ms/epoch - 4ms/step\n",
            "Epoch 126/150\n",
            "18/18 - 0s - loss: 33.1954 - val_loss: 35.4572 - 83ms/epoch - 5ms/step\n",
            "Epoch 127/150\n",
            "18/18 - 0s - loss: 29.7133 - val_loss: 35.7035 - 79ms/epoch - 4ms/step\n",
            "Epoch 128/150\n",
            "18/18 - 0s - loss: 34.2183 - val_loss: 36.3222 - 75ms/epoch - 4ms/step\n",
            "Epoch 129/150\n",
            "18/18 - 0s - loss: 33.4362 - val_loss: 36.2139 - 100ms/epoch - 6ms/step\n",
            "Epoch 130/150\n",
            "18/18 - 0s - loss: 33.0939 - val_loss: 35.8293 - 74ms/epoch - 4ms/step\n",
            "Epoch 131/150\n",
            "18/18 - 0s - loss: 36.6841 - val_loss: 38.3000 - 73ms/epoch - 4ms/step\n",
            "Epoch 132/150\n",
            "18/18 - 0s - loss: 35.6372 - val_loss: 52.1681 - 78ms/epoch - 4ms/step\n",
            "Epoch 133/150\n",
            "18/18 - 0s - loss: 40.1537 - val_loss: 41.3196 - 85ms/epoch - 5ms/step\n",
            "Epoch 134/150\n",
            "18/18 - 0s - loss: 34.7606 - val_loss: 39.7357 - 81ms/epoch - 5ms/step\n",
            "Epoch 135/150\n",
            "18/18 - 0s - loss: 37.1255 - val_loss: 40.5202 - 84ms/epoch - 5ms/step\n",
            "Epoch 136/150\n",
            "18/18 - 0s - loss: 42.3217 - val_loss: 48.8883 - 87ms/epoch - 5ms/step\n",
            "Epoch 137/150\n",
            "18/18 - 0s - loss: 33.4262 - val_loss: 39.5310 - 82ms/epoch - 5ms/step\n",
            "Epoch 138/150\n",
            "18/18 - 0s - loss: 31.5063 - val_loss: 38.3964 - 83ms/epoch - 5ms/step\n",
            "Epoch 139/150\n",
            "18/18 - 0s - loss: 31.1755 - val_loss: 34.4941 - 83ms/epoch - 5ms/step\n",
            "Epoch 140/150\n",
            "18/18 - 0s - loss: 30.6750 - val_loss: 33.4099 - 91ms/epoch - 5ms/step\n",
            "Epoch 141/150\n",
            "18/18 - 0s - loss: 40.1079 - val_loss: 35.7737 - 96ms/epoch - 5ms/step\n",
            "Epoch 142/150\n",
            "18/18 - 0s - loss: 43.0645 - val_loss: 47.2196 - 70ms/epoch - 4ms/step\n",
            "Epoch 143/150\n",
            "18/18 - 0s - loss: 34.4002 - val_loss: 35.8465 - 83ms/epoch - 5ms/step\n",
            "Epoch 144/150\n",
            "18/18 - 0s - loss: 29.2399 - val_loss: 37.5822 - 80ms/epoch - 4ms/step\n",
            "Epoch 145/150\n",
            "18/18 - 0s - loss: 30.1894 - val_loss: 34.1251 - 86ms/epoch - 5ms/step\n",
            "Epoch 146/150\n",
            "18/18 - 0s - loss: 29.7694 - val_loss: 52.3660 - 92ms/epoch - 5ms/step\n",
            "Epoch 147/150\n",
            "18/18 - 0s - loss: 31.8882 - val_loss: 35.5427 - 87ms/epoch - 5ms/step\n",
            "Epoch 148/150\n",
            "18/18 - 0s - loss: 35.4413 - val_loss: 35.2802 - 77ms/epoch - 4ms/step\n",
            "Epoch 149/150\n",
            "18/18 - 0s - loss: 31.2969 - val_loss: 34.3251 - 77ms/epoch - 4ms/step\n",
            "Epoch 150/150\n",
            "18/18 - 0s - loss: 29.1671 - val_loss: 37.0996 - 82ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f75ea85ec80>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred= model_11.predict(X_test)\n",
        "# Evaluate the model\n",
        "mse = model_11.evaluate(X_test, y_test, verbose=0)\n",
        "print('Mean Squared Error:', mse)\n",
        "\n",
        "# Calculate R-squared error\n",
        "from sklearn.metrics import r2_score\n",
        "model_11_r2 = r2_score(y_test, y_pred)\n",
        "print('R-squared Error:', model_11_r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKJL-nxEvS4R",
        "outputId": "8f3e06c2-5307-4333-cd33-50de99f57e16"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error: 40.88431930541992\n",
            "R-squared Error: 0.8413349357255497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*By increasing the number of neurons in the dense layers and extending the training duration to 150 epochs, the model's performance has improved. The Mean Squared Error (MSE) has decreased to 40.88, indicating that the average squared difference between the predicted and actual values in the test data has reduced. Additionally, the R-squared Error has increased to 0.841, suggesting that approximately 84.1% of the variance in the dependent variable is explained by the independent variables in the model. These improvements indicate that the updated model architecture and training settings have led to enhanced predictive accuracy and a better fit to the data. Overall, this signifies a step in the right direction towards building a more effective regression model for your task.*"
      ],
      "metadata": {
        "id": "VmFcZkLqvs5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble Regression Model without Dropout**\n",
        "\n",
        "*Exploring avenues to enhance our model's accuracy, we're now delving into ensemble learning with five distinct models. Ensemble techniques amalgamate predictions from multiple models to elevate overall performance, offering a robust solution for complex regression tasks. As we embark on this advanced approach, we're also evaluating the impact of dropout regularization on our model's performance. Dropout, a common regularization technique in neural networks, helps prevent overfitting by randomly dropping neurons during training.*\n",
        "\n",
        "*By temporarily disabling dropout, we can assess the model's performance in its original configuration, providing valuable insights into the effectiveness of dropout regularization in improving generalization. Let's dive in to compare our ensemble model's performance with and without dropout regularization, aiming for greater accuracy and reliability in our predictions.*"
      ],
      "metadata": {
        "id": "5Vab11zxJ4pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_models = 5\n",
        "models_1 = []\n",
        "\n",
        "for i in range(num_models):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1))  # Output layer, no activation function for regression\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "    models_1.append(model)\n"
      ],
      "metadata": {
        "id": "XGa5UbTBETbo"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using each individual model\n",
        "predictions = np.zeros((X_test.shape[0], num_models))\n",
        "for i, model in enumerate(models_1):\n",
        "    predictions[:, i] = model.predict(X_test).flatten()\n",
        "\n",
        "# Average predictions\n",
        "ensemble_prediction = np.mean(predictions, axis=1)\n",
        "\n",
        "# Calculate ensemble model performance\n",
        "ensemble_mse = np.mean((ensemble_prediction - y_test)**2)\n",
        "print('Ensemble Mean Squared Error:', ensemble_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aermh2o_EoFt",
        "outputId": "8ab23512-d5bd-4f90-a5c0-6265ff21f70a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Ensemble Mean Squared Error: 45.456356275258344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Taking a closer look at our ensemble regression model's performance, we've achieved a significant improvement, with an Ensemble Mean Squared Error (MSE) of 45.45. This metric essentially tells us how close our model's predictions are to the actual values in our dataset. So, with a lower MSE like this, it means our model's predictions are much closer to reality on average, indicating a substantial boost in predictive accuracy. This improvement from our previous iterations suggests that our ensemble approach, which combines insights from multiple models, has really paid off. It's effectively captured the underlying patterns in our data, leading to more precise predictions. Overall, our ensemble regression model is showing great promise, delivering more accurate and reliable results for our regression tasks.*"
      ],
      "metadata": {
        "id": "xJIDFlkycgqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R-squared for the ensemble model\n",
        "ensemble_r2 = r2_score(y_test, ensemble_prediction)\n",
        "print('Ensemble R-squared:', ensemble_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AEY1Ux2FIBa",
        "outputId": "fdd11585-0228-47c5-b923-d7593b74fb78"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble R-squared: 0.8235916480304465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Our ensemble regression model achieves an impressive Ensemble R-squared value of 0.823, indicating a strong fit to the data. This high R-squared value underscores the model's effectiveness in capturing the underlying patterns within the dataset and making accurate predictions. Overall, our ensemble approach proves successful in addressing regression tasks with precision and reliability.*"
      ],
      "metadata": {
        "id": "SgQQMR02dBav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble regression Model with Dropout**\n",
        "\n",
        "*Taking our ensemble regression model to the next level, we're introducing dropout regularization into the mix. Dropout acts like a team-building exercise for our neurons, randomly 'dropping out' some during training to ensure each neuron learns to stand on its own and not become overly dependent on others. By adding dropout to our ensemble model, we're essentially giving it a bit of a shake-up to see how it performs. Join us on this journey as we explore the fascinating dynamics of dropout regularization and its potential to fine-tune our model's predictive prowess.*"
      ],
      "metadata": {
        "id": "FywMtwDVKKiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout\n",
        "# Assuming you have already loaded and preprocessed your data\n",
        "# X: Features, y: Target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Number of individual models in the ensemble\n",
        "num_models = 5\n",
        "models_2 = []\n",
        "\n",
        "# Train individual models with dropout\n",
        "for i in range(num_models):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dropout(0.2))  # Dropout layer with 20% dropout rate\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.2))  # Dropout layer with 20% dropout rate\n",
        "    model.add(Dense(1))  # Output layer, no activation function for regression\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "    models_2.append(model)\n",
        "\n",
        "# Make predictions using each individual model\n",
        "predictions = np.zeros((X_test.shape[0], num_models))\n",
        "for i, model in enumerate(models_2):\n",
        "    predictions[:, i] = model.predict(X_test).flatten()\n",
        "\n",
        "# Average predictions\n",
        "ensemble_prediction = np.mean(predictions, axis=1)\n",
        "\n",
        "# Calculate R-squared for the ensemble model\n",
        "ensemble_r2 = r2_score(y_test, ensemble_prediction)\n",
        "print('Ensemble R-squared:', ensemble_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XygDwKwKFZb0",
        "outputId": "17b87150-9f40-4d15-ceb2-5327fcff6880"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Ensemble R-squared: 0.4079130746659957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*With the addition of dropout regularization at a rate of 20%, our model_2 achieved an Ensemble R-squared score of 0.407. This indicates that our model's ability to explain the variance in the data has been somewhat reduced compared to previous iterations. Dropout regularization, while beneficial for preventing overfitting, may have introduced some level of uncertainty or variability in the model's predictions. Therefore, while our ensemble model with dropout regularization still demonstrates a reasonable fit to the data, it appears to be less effective in capturing the underlying patterns compared to earlier versions without dropout. This suggests that the trade-off between reducing overfitting and preserving predictive accuracy may need to be carefully balanced in future model iterations.*"
      ],
      "metadata": {
        "id": "oWyeBrW1eXtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble Regression Model with Batch Normalization**\n",
        "\n",
        "*Adding another layer of refinement to our ensemble regression model, we're incorporating **batch normalization**. Batch normalization is a technique that normalizes the inputs of each layer, ensuring that the model trains more efficiently and improves its overall stability. By integrating batch normalization into our ensemble model, we aim to further enhance its performance and robustness.*\n",
        "\n",
        "*Stay tuned as we explore the impact of batch normalization on our model's predictive accuracy and uncover any intriguing insights it may reveal.*"
      ],
      "metadata": {
        "id": "C_vIYQOpKjK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import  BatchNormalization\n",
        "\n",
        "# Number of individual models in the ensemble\n",
        "num_models = 5\n",
        "models_3 = []\n",
        "\n",
        "# Train individual models with batch normalization\n",
        "for i in range(num_models):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(BatchNormalization())  # Batch normalization layer\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(BatchNormalization())  # Batch normalization layer\n",
        "    model.add(Dense(1))  # Output layer, no activation function for regression\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "    models_3.append(model)\n",
        "\n",
        "# Make predictions using each individual model\n",
        "predictions = np.zeros((X_test.shape[0], num_models))\n",
        "for i, model in enumerate(models_3):\n",
        "    predictions[:, i] = model.predict(X_test).flatten()\n",
        "\n",
        "# Average predictions\n",
        "ensemble_prediction = np.mean(predictions, axis=1)\n",
        "\n",
        "# Calculate R-squared for the ensemble model\n",
        "ensemble_r2 = r2_score(y_test, ensemble_prediction)\n",
        "print('Ensemble R-squared:', ensemble_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sutxnpc4Fyt-",
        "outputId": "c41ca695-a858-4cf0-ef5c-fb9d303e6571"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Ensemble R-squared: 0.8720764791065443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*After integrating batch normalization into our ensemble regression model, we observed a significant improvement in performance. Model_3 achieved an impressive **Ensemble R-squared score of 0.872**, showcasing its enhanced ability to explain the variance in our dataset. This marks a notable advancement compared to previous iterations, which achieved Ensemble R-squared scores of 0.822 and 0.407.*\n",
        "\n",
        "*For our concrete_data.csv dataset, model_3 with batch normalization emerges as the top performer, offering superior accuracy and reliability for regression tasks. This enhancement underscores the importance of advanced techniques like batch normalization in improving model performance and underscores our commitment to pushing the boundaries of machine learning excellence.*"
      ],
      "metadata": {
        "id": "lJVkAfnogB-_"
      }
    }
  ]
}